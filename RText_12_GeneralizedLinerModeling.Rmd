---
title: "回帰モデルの発展：一般化線形モデル"
author: "藤野秀則"
date: 
  初稿日:"2024-10-15"
  更新日:`r Sys.Date()`
output:
  html_document: 
    toc: true
    toc_depth: 4
    toc_float: true
    number_section: true
    fig_width: 8
    css: ./style.css
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

これまでの回帰分析では，**目的変数は連続変数であり，かつ，誤差項（=目的変数の予測値と実測値の差）は正規分布に従っている**という仮定のもとで回帰分析を行ってきた．しかし，目的変数が連続変数であるとは限らず，また，目的変数の誤差が正規分布に従っているとも限らない場合もある．このような場合には，**一般化線形モデル（Generalized Linear Model: GLM）**を用いることが適している．

GLMは文字通り，様々な目的変数や誤差項の分布に対応できるモデルであり，そのバリエーションは非常に多い．ここでは，その中でも最も一般的な**ロジスティック回帰分析**，**プロビット回帰分析**，**ポアソン回帰分析**について解説する．

# ロジスティック回帰分析

ロジスティック回帰分析は，従属変数が二値変数（0または1）である場合に適用される．例えば，ある商品を購入するかどうか（購入する場合は1，しない場合は0）を予測する場合などに用いられる．


:::ref
<details>
<summary>ロジスティック回帰分析の詳細な説明</summary>
普通の回帰分析は，目的変数は連続変数であるという前提の下，説明変数を用いて目的変数$y$の値そのものを予測する式を作ろうとするのに対して，
ロジスティック回帰分析では目的変数$y$は0か1という2値であるという前提のもとで，$y$の値そのものではなく，$y=1$となる**確率**を推定しようという分析である．

そして，通常の回帰分析（特に単回帰分析）では，「目的変数$y$と説明変数$x$との関係は$y=a+\boldsymbol{b}\times \boldsymbol{x}$という直線（1次関数）の関係にある」という仮定を置いて，$x$に対する$y$の実測値と予測値の誤差がデータ全体で最も小さくなるように$a$と$b$を求める，ということをするのに対して，
ロジスティック回帰分析では，確率$P_{y=1}$と説明変数$x$との関係は**ロジスティック関数**と呼ばれる以下のような式によって表現される，という仮定を置いて，この関数のパラメータ$a$と$\boldsymbol{b}$をデータから推定する（わかりやすさの為に説明変数が1つの場合を用いているが，説明変数が複数ある場合も．

$$
P_{y=1} = \frac{1}{1+\exp{(-(a+\boldsymbol{b}\times \boldsymbol{x})}}\\ \\
\left(=\frac{1}{1+\frac{1}{\exp{(a+\boldsymbol{b}\times \boldsymbol{x})}}}= \frac{\exp{(a+\boldsymbol{b}\times \boldsymbol{x})}}{1+\exp{(a+\boldsymbol{b}\times \boldsymbol{x})}} \right)
$$


この式の中で，$\exp()$は自然対数の底，もしくはネイピア数（2.71828...）の指数関数である．すなわち$\exp(x)=e^x$である．

このロジスティック関数の特徴は，$x$がどんな値であっても$P$は0から1の間の値を取ることである．
この関数の形状は以下のようになる．

```{r echo=FALSE}
x <- seq(-10, 10, 0.1)
y <- 1/(1+exp(-x))
plot(x, y, type = "l", xlab = "x", ylab = "y")
```

つまり，$x=0$を境に$x$が増加すればするほど，$P$は1に近づく．つまり，目的変数$y$は1である確率が高まる(=$y$が0である確率が低まる）．逆に$x$が減少すればするほど，$P$は0に近づく．つまり，目的変数$y$は1である確率が低まる（=$y$が0である確率が高まる）．

こうしたことから，ロジスティック関数を当てはめることによって，ある$x$が充てられたときに，目的変数が0か1のいずれの値を取る可能性が高のかを予測することができるようになる．

なお，普通の回帰分析では目的変数$y$は連続変数であるということに加えて，$y$の実測値と予測値の差の分布は正規分布で表現される）という仮定を置いている．一方，ロジスティック回帰分析では目的変数$y$は0，1の2値変数であるため，$y$が0,1のいずれの値になるか（つまり$y$の確率分布）は**二項分布**に従っているという仮定が置かれる．
</details>
:::

:::ref
<details>
<summary>ロジスティック関数とロジット変換</summary>
ロジスティック回帰分析におけるモデル式は上記の通り，ロジスティック関数によって表記されるが，この関数を線形回帰分析の式に変換することもできる（なお，以下で$\ln$は自然対数を表す）．

\begin{align}
P &= \frac{1}{1+e^{-(a+b\times x)}} \\

\frac{1}{P} &= 1+e^{-(a+b\times x)} \\

\frac{1}{P}-1 &= e^{-(a+b\times x)} \\

\frac{1-P}{P} &= e^{-(a+b\times x)} \\

\ln{\left(\frac{1-P}{P}\right)} &= -(a+b\times x) \\

\therefore \ \ \ln{\left(\frac{P}{1-P}\right)} &= a+b\times x
\end{align}


このような変換をロジット変換と呼ぶ．このロジット変換を行うと，左辺は対数オッズ比（log odds）となる．対数オッズは，ある事象が起こる確率と起こらない確率の比率を対数変換したものであり，この値が正の値を取れば取るほど，その事象が起こる確率が高まることを示す．
</details>
:::

:::practice
[このデータ](./practice/example_11_Logistic.csv)は，ある店舗のPOSデータからランダムサンプリングした来店者500人分の性別（0:男，1:女），年齢帯（10～70まで10年刻み），来店時間帯（9時～22時まで1時間刻み）と，その人がとある新製品を購入したかどうか（0:購入していない，1:購入した）を記録したデータである．このデータをもとに，ある来店客の性別・年齢帯・来店時間帯からその客が新製品を買うか買わないかを予測する式を立てよ．

```{r include=FALSE}
library(tidyverse)
set.seed(123)
Sex <- sample(0:1, 500, replace = TRUE)  
Age <- sample(10:79, 500, replace = TRUE) %/%10 * 10

# 小さな山（10時台）：平均10, 標準偏差1の正規分布からサンプリング
base_customers <- sample(9:22, 150, replace = TRUE) 
morning_customers <- round(rnorm(50, mean = 10, sd = 1),0)
# 大きな山（17時台）：平均17, 標準偏差1の正規分布からサンプリング
evening_customers <- round(rnorm(300, mean = 17, sd = 2),0)
# 両方の分布から生成されたデータを結合
Time <- c(base_customers, morning_customers, evening_customers)
# 時間帯を9時から22時の範囲に収めるために四捨五入し、範囲外を9-22に修正
Time <- ifelse(Time < 9, 9, ifelse(Time >= 22, 22, Time))

# したかどうか
Buy <- 1/(1+exp(-(0.4*Sex + 0.21*Age + 0.4*Time + 2*rnorm(500, 0, 0.5)))) 
Buy <- ifelse(Buy > mean(Buy), 1, 0)

data <- data.frame(
  性別 = Sex,
  年齢 = Age,
  時間帯 = Time,
  購入 = Buy
)

write.csv(data, file = "Example_11_Logistic.csv", row.names = FALSE)
```

:::

Rでロジスティック回帰分析を行うためには，`glm`関数を用いる．
第1引数には，`目的変数 ~ 説明変数1 + 説明変数2 + ...`という形式で指定する．
第2引数には，`data`引数にデータを指定する．
第3引数には，`family`引数に`binomial`(二項分布)を指定する．

```{r}
data <- read.csv("Example_11_Logistic.csv")
fit <- glm(購入 ~ 性別 + 年齢 + 時間帯, data = data, family = binomial)
summary(fit)
```

この結果から，この新製品を購入するかどうかを予測する式は以下のようになる．

$$
P = \frac{1}{1+\exp{(-(-14.7+0.323 \times \text{性別} + 0.398 \times \text{年齢} + 0.647 \times \text{時間帯})})}
$$ 


$$
\therefore \ln \left( \frac{p}{1-p} \right) = -14.7+0.323 \times \text{性別} + 0.398 \times \text{年齢} + 0.647 \times \text{時間帯}
$$

## オッズ比
ロジスティック回帰分析で得られる各回帰係数の値は，上記の式からも分かる通り各説明変数が1だけ変化したとき（その他の説明変数は一定であると仮定）に，$\ln(\frac{P}{1-P})$がどれだけ変化するかを示す．ただ，$\ln(\frac{P}{1-P})$は直感的には理解し辛いので，これをオッズ比$\frac{P}{1-P}$に変換するのが一般的である．オッズ比への変換は極めて簡単で，各説明変数の回帰係数を指数関数にかけるだけである．

:::ref
<details>
<summary>オッズ比とは</summary>
オッズ比（Odds Ratio）は，ある事象が起こる確率と起こらない確率の比である．たとえば，AとBが試合をするとき，Aが勝つ確率が0.6であるとすると，Aが負ける確率は0.4である（引き分けは考慮しない）．このとき，Aが勝つ確率と負ける確率の比率は0.6/0.4=1.5である．つまり，Aが勝つ確率はAが負ける確率の1.5倍だと言える．このように，ある事象yが起こる確率が起こらない確率の何倍なのかを示すのがオッズ比である．
</details>
:::

各説明変数は`coef()`関数で得られるので，これに`exp()`関数を適用することでオッズ比を求めることができる．
また`confint()`関数を用いることで，各説明変数の信頼区間を求めることもできる．


```{r}
# 各説明変数の回帰係数
coef(fit)
# 各説明変数のオッズ比
exp(coef(fit))
# 各説明変数の信頼区間
confint(fit)
# オッズ比の信頼区間
exp(confint(fit))
```
なお，今回のデータの場合，`confint()`を実行した際に警告メッセージが多数表示される．これについては[後程](#完全分離の問題)触れる．

## モデルの適合度

モデル全体の適合度を見る指標として，単純な回帰分析では決定係数やF値が用いられるが，ロジスティック回帰分析では以下のような指標が用いられる．

- **Null DevianceとResidual Deviance**：残差逸脱度．説明変数を使わない場合(Nullモデル)と説明変数を使った場合とで，逸脱度(Deviance)がどれだけ変化したかを見る．この差が大きいほど，説明変数が目的変数を説明していると言える．
- **擬似$R^2$**：決定係数に相当する指標．1に近いほど説明力が高いとされる．残差逸脱度を用いて以下の式で得られる．
$$
\text{McFadden's }R^2 = 1-\frac{\text{Residual Deviance}}{\text{Null Deviance}}
$$
- **対数尤度（Log Likelihood）**: 高い値であるほど適合度が高いとされる．対数尤度の注意点として，この値単独でモデルの適合度を評価できるものではなく，あくまで他のモデルとの比較のための指標である.
- **AIC**：赤池情報量規準（Akaike's Information Criterion）．AICが小さいほど，モデルの適合度が高いと言える．AICも対数尤度と同様に他のモデルとの比較のための指標である．
- **BIC**：ベイズ情報量規準（Bayesian Information Criterion）．BICが小さいほどモデルの適合度が高いとされる．BICも対数尤度と同様に他のモデルとの比較のための指標である．

これらの指標は通常，`summary()`関数で得られる結果に含まれているが，場合によっては別途計算することもある．特によく用いられるのは，AICやBIC，対数尤度であるが，これらはそれぞれ以下のように簡単に求められる関数が用意されている．

```{r}
# 対数尤度
logLik(fit)
# AIC
AIC(fit)
# BIC
BIC(fit)
```

:::ref
<details>
<summary>対数尤度，AIC，BICの詳細な説明</summary>
対数尤度，AIC，BICはいずれも尤度（likelihood）を基に算出される指標である．
では，尤度とはどういうものだろうか．

尤度とは，手許にあるデータから目的変数を予測するモデル式を立てた時に，その予測式のモデルと目的変数の確率分布の下で実際に観測されたデータが得られる確率を表す．

たとえば，説明変数を$X$とし，目的変数$Y$は正規分布に従っている（[注1](#尤度注1)）と仮定する単回帰モデルにおいて，ある観測データ$(x_{i},y_i)$が得られる確率（$X=x_i$のときに$Y=y_i$となる確率）は，正規分布の確率密度関数を用いて以下のように表される．
$$
\begin{align}
P(Y=y_i|X_1=x_{i}) 
& = \frac{1}{\sqrt{2\pi\sigma^2}}\exp{\left(
-\frac{(y_i-\mu_{x_i})^2}{2\sigma^2}\right)}\\
& =\frac{1}{\sqrt{2\pi\sigma^2}}\exp{\left(
-\frac{(y_i-\beta_0-\beta_1x_{i})^2}{2\sigma^2}\right)}\ \ \ \because \mu_{x_i} = \beta_0+\beta_1x_{i}
\end{align}
$$
このようにして推定された回帰モデルの下で，各観測値$(x_i, y_i)$が得られる確率$P(y_i|x_i)$をそれぞれ求めることができる．そして，尤度とはそれらの確率をすべて掛け合わせたものである．

$$
L = P(y_1|x_1) \times P(y_2|x_2) \times ... \times P(y_n|x_n)=\prod_{i=1}^{n}P(y_i|x_i)
$$
ロジスティック回帰モデルの場合には目的変数が二項分布に従っていると仮定されおり，また，説明変数$X$に対して目的変数が1となる確率はロジスティック関数を用いて表現される．よって，ある観測値$(x_i, y_i)$が得られたときに，現在のロジスティック回帰モデルの下でその観測値が得られる確率は以下のように表現される．

$$
\begin{align}
&y_i=1のとき　P(y_i|x_i)=\frac{1}{1+\exp({-(a+b\times x_i)})}\\
&y_i=0のとき　P(y_i|x_i)=1-\frac{1}{1+\exp({-(a+b\times x_i)}}
\end{align}
$$
この2つ式は以下のようにまとめることができる（[注2](#尤度注2)）．
$$
P(y_i|x_i) = P^{y_i} (1-P)^{1-{y_i}}=\left(\frac{1}{1+\exp({-(a+b\times x_i)})}\right)^{y_i}\left(1-\frac{1}{1+\exp({-(a+b\times x_i)})}\right)^{1-{y_i}}
$$
このようにして各観測値に対して，そのような観測値が得られる確率を求め，それらをすべて掛け合わせたものがロジスティック回帰モデルにおける尤度となる．

こうのように尤度とは，**各観測値が従っていると仮定されているモデル式と目的変数に仮定されている確率分布から，実際に観測されたデータが得られる確率をすべての観測に対して求め，それらを掛け合わせてもの**として定義される．

尤度は確率（つまりは小数）の値をサンプル数分だけ掛け合わせることによって得られるものであるため，サンプル数が多くなれば多くなるほど，尤度の値は極端に小さくなる．尤度をそのまま使うのは不便なため，尤度の自然対数を取ったものが**対数尤度（log likelihood）**である．対数を取ることで尤度の値が小さくなりすぎることを防ぐことができる．

そしてこれを用いて以下の式で計算されるのがAIC，BICである．ここでkはモデルに含まれる推定パラメータの数（切片，説明変数の数），nは標本の大きさである．

$$
\begin{align}
\text{AIC} &= -2 \ln(L) +2k \\
\text{BIC} &= -2 \ln(L) +k\ln(n)
\end{align}
$$


<a name="尤度注1">注1：</a>
回帰分析においては，yの実測値は回帰直線の回りにばらついて存在しているが，そのばらつき方は各xに対して一定で，かつ正規分布をしていると仮定されている．また，この時の$\sigma$は目的変数yが回帰直線の回りでどの程度ばらついているかを示す標準偏差であり，回帰分析を行った際に得られる残差（Residuals）を自由度で割ったもの（平均平方）である．
![回帰直線と実測値およびバラツキの様子](./Img/2024_10_13_Likelihood.png)
<a name="尤度注2">注2：</a>
$y_i=1$の時は$P^{y_i}=P, (1-P)^{1-{y_i}}=1$となり，結局$P$となる．逆に$y_i=0$の時は$P^{y_i}=1, (1-P)^{1-{y_i}}=1-P$となり，結局$1-P$となる

</details>
:::


## 完全分離の問題


実は，今回の例では信頼区間を求める際に警告メッセージが多く表示される．
これは各説明変数の値の組み合わせに，目的変数（購入）が0，ないし1しか存在しない組み合わせが存在しているためである．
例えば，今回のデータの場合，「女性，10代，9時台来店」の組み合わせでは購入した人がいない．つまり目的変数の値がすべてのサンプルで0となる．
このように，ある特定の説明変数値の組み合わせの場合に0ないし1に目的変数が特定できてしまう場合のことを**完全分離**と呼ぶ．完全分離が含まれているデータでは，ロジスティック回帰分析の結果は信頼できないものとなり，このような警告メッセージが表示される．

なお，今回，警告メッセージは，`confint()`関数実行時に表れたが，場合によっては`glm()`実行時にも表れることがある．いずれにせよ，こうした警告メッセージが現れてしまった場合，glmの結果もconfintの結果も信頼できないものとなるため，注意が必要である．

実際のデータで多くのサンプルを利用している場合には，完全分離になるケースが含まれる可能性は下がるため，こうした問題が起こることはそう多くはないが，サンプル数が少ない場合には発生する可能性がある．そうした完全分離を含むデータに対してロジスティック回帰分析を行いたい場合の対処法として「Firthのバイアス補正法」が提案されている．

Firthのバイアス補正法を適用したロジスティック回帰分析の実施には，以下の2つの方法がある．

- `logistf`パッケージに含まれる`logistf()`関数を用いる（予め`logistf`パッケージをインストールしておく必要がある）．

- `brglm2`パッケージを読み込んだうえで，`glm()`の結果を収めたオブジェクトに対して`Update()`関数を掛ける（予め`brglm2`パッケージをインストールしておく必要がある）．

関数内部での数値計算の方法や小数の扱い方の違いによってわずかな数値の違いが生じることはあるが，ほぼ同じ結果を返す．

### ligstrfパッケージを用いた場合
まずはligstrf関数を用いた場合の実行方法を示す．
```{r} 
# インストールしたパッケージの読み込み
library(logistf) 
#分析実行　第3引数family=binomialの指定は不要
fit_logistf <- logistf(購入 ~ 性別 + 年齢 + 時間帯, data = data )
#結果の出力
summary(fit_logistf)

```
logistf関数を用いた場合には，
`coef`が分析で得られた回帰係数の推定値，`se(coef)`は推定値の標準誤差，`lower 0.95`と`Upper 0.95`が95%信頼区間の下限と上限，pが有意確率である．
このようにlogistf関数を用いると，信頼区間（それぞれの値）もまとめて表記してくれる．


:::ref
<details>
<summary>methodについて</summary>
各回帰係数の結果表記の最後の列のmethodは信頼区間を計算するときにどの方法を用いたかを示すものである．1のWald法の場合は$回帰係数±1.96×標準誤差$で信頼区間を求めている(この計算方法は広く一般に信頼区間を求める際に用いられる方法である)．2はペナルティ付きプロファイル尤度法と呼ばれる方法で，これがバイアス補正法にあたる（通常のConfint()関数はペナルティを付けない通常のプロファイル尤度法によって信頼区間を求めている）．3はNoneということで，信頼区間の算出を行わない設定の場合に3となるが通常現れることはないだろう．
</details>
:::
このように`logistf()`は信頼区間まで一気に算出してくれる，という利点がある一方で，`summary()`の結果として表示される適合度は尤度比検定とWald検定の結果であり一般に良く用いられる対数尤度やAIC，BICの表記がない．また`AIC()`や`BIC`，`logLik()`などの適合度指標を得るための関数は利用できない，という欠点がある（但し，対数尤度は取得可能であり，そこから手計算させることは可能である）．

:::ref
<details>
<summary>logistf()の結果からの対数尤度の取得方法</summary>
以下のようにすれば対数尤度は得られる．
```{r}
fit_logistf$loglik["full"] #フルモデルの対数尤度
fit_logistf$loglik["null"] #Nullモデルの対数尤度
```
</details>
:::

:::ref
<details>
<summary>尤度比検定</summary>
尤度比検定とは説明変数を1つ置かないモデル（Nullモデル）の尤度に対して，説明変数を置いたモデル（予測モデル）の尤度がどれだけ改善したかを検定する方法である．具体的には，以下のような式で計算される統計量が$\chi^2$分布に照らしてどの程度の有意確率かを調べることによって，予測モデルが有意にモデルの適合度を向上させたか，すなわち，説明変数を設けることに意味があるかどうかを検証する．
$$
統計量= -2 \times \log\left(\frac{\text{Nullモデルの尤度}}{\text{予測モデルの尤度}}\right)
$$
</details>
:::

:::ref
<details>
<summary>Wald検定</summary>
Wald検定は，もともとは各回帰係数が有意かどうか（回帰係数が0であるという帰無仮説を棄却できるか）を検定するための方法である．Wald検定は以下の式で計算される統計量が標準正規分布に照らしてどの程度の有意確率かを調べることによって，各回帰係数が有意かどうかを検証する．

$$
統計量W= \frac{\text{回帰係数}}{\text{回帰係数の標準誤差}}
$$

これをモデル全体に拡張させると，「すべての回帰係数が0である」ということを帰無仮説とする検定となり，そのための検定統計量は以下のようになる([参考](#Hosmer))．
$$
統計量W=\hat{\beta'}\left[\hat{\text{Var}}(\hat{\beta})\right]^{-1}\hat{\beta} 
$$
ここで，$\hat{\beta}$は推定された回帰係数ベクトル，$\hat{\beta'}$はその転置形，$\hat{\text{Var}}(\hat{\beta})$は推定された回帰係数の分散共分散行列である．これらの内積を取ることで統計量Wが求められる．

実際に先のlogistf()の結果を基にRで計算すると以下の通りとなる．
```{r}
#回帰係数の推定値
B=coef(fit_logistf)
#回帰係数の分散共分散行列
V=vcov(fit_logistf)
#分散共分散行列の逆行列
V_inv=solve(V)
#統計量Wの計算
W=B%*%V_inv%*%B # %*%は行列の内積を表す演算子
#出力
print(W)
```


このWは説明変数の数を自由度とする$\chi^2$分布に従うので，そこから有意確率を求め，帰無仮説を棄却できるかどうかを判断する．

<a name="Hosmer">参考：</a>

- Daivid W. Hosmer, Applied Logistic Regression second edition, 2000, p.39
- 古川敏仁, Logistic 回帰モデルにおける Wald 検定と TypeⅢ型検定, http://www.biostar.co.jp/ALR_1.pdf（2024年10月13日閲覧）

</details>
:::




オッズ比やオッズ比の信頼区間は先と同様にexp()関数を用いて求めることができる．

```{r}
#オッズ比
exp(coef(fit_logistf))
#オッズ比の信頼区
exp(confint(fit_logistf))
```

### brglm2パッケージを用いた場合
続いてbrglm2パッケージを用いた場合の実行方法を示す．
ポイントは一旦，そのまま`glm()`を実行したうえで，glm()の結果を収めたオブジェクトに`Update()`関数を掛ける，という点である．`Update()`関数は第1引数にglm()の結果を収めたオブジェクト，第2引数には`method="brglmFit"`を与える．
```{r}
# インストールしたパッケージの読み込み
library(brglm2) 
#普通にglmを実行
fit <- glm(購入 ~ 1+性別 + 年齢 + 時間帯, data = data, family=binomial)
# バイアス低減法を適用
fit_brglm2 <- update(fit, method="brglmFit")
#結果の出力
summary(fit_brglm2)
```

このようにして得られた結果は`glm()`と同じ構造を持つオブジェクトであるため，オッズ比や信頼区間，適合度指標を求める方法も`glm()`と同様の方法で求めることができる．

```{r}
#オッズ比
exp(coef(fit_brglm2))
#オッズ比の信頼区
exp(confint(fit_brglm2))
# AIC
AIC(fit_brglm2)
# BIC
BIC(fit_brglm2)
# 対数尤度
logLik(fit_brglm2)
```


## 結果の報告
ロジスティック回帰分析の結果を報告する場合には，glmのsummary関数で得られる各係数の値（対数オッズ比）ではなく，**オッズ比とその有意性を報告するのが一般的**である．

以下，結果報告の例を示す．この例では各説明変数のオッズ比，有意性とオッズ比の信頼区間を報告している．また適合度を示す指標として，対数尤度とAICを報告している．適合度指標としてこれらを表記するのは，この研究では(1)～(3)という3つのモデルの比較をしているためであると考えられる．(1)は統制変数をモデルに加えずに分析したモデル，(2)は統制変数をモデルに加えたモデル，(3)はさらに交互作用項も加えたモデルである．


![ロジスティック回帰分析の結果報告の例](./Img/2024_10_12_LogiReg.png)
(出典：Alzen, J.L., Langdon, L.S. & Otero, V.K. A logistic regression investigation of the relationship between the Learning Assistant model and failure rates in introductory STEM courses. International Journal of STEM Education Vol.5, No.56 (2018). https://doi.org/10.1186/s40594-018-0152-1)


## 標準化ロジスティック回帰分析

単純な回帰分析の場合と同様に，ロジスティック回帰分析でも各説明変数の回帰係数の値やオッズ比では単位に依存してしまうため，目的変数に対する影響の強さを説明変数間で比較することはできない．そのため，説明変数の単位に依存しないように，説明変数を標準化してからロジスティック回帰分析を行うことがある．

注意しなければならない点として，ダミー変数（今回の例であれば「購入」「性別」）は標準化してはならない点である．ダミー変数は0と1という2値の数字ではあるものの，もとは質的でカテゴリカルな概念であり，例えば0.5という値は概念として存在していないはずだからである．標準化するということは平均や標準偏差を考えることになり，こうした「小数」を考慮することになる．このためダミー変数は0, 1の値のまま分析に掛ける．

標準化の方法として，単純な回帰分析の場合にはデータ全体を標準化してしまう（`data=as.data.frame(scale(data))`にしてしまう）のが楽なのだが，ロジスティック回帰分析の場合にはダミー変数や目的変数は元のままで置いておく必要があるので，モデル式の中で個別に説明変数に`scale()`関数を適用するほうが楽だろう．


```{r}
fit_scaled <- glm(購入 ~ 性別 + scale(年齢) + scale(時間帯), data = data, family = binomial)
summary(fit_scaled)
# 標準化されたオッズ比
exp(coef(fit_scaled))
# 標準化されたオッズ比の信頼区間
exp(confint(fit_scaled))

# 完全分離データの場合はこちら
fit_firth_scaled <- logistf(購入 ~ 性別 + scale(年齢) + scale(時間帯), data = data )
summary(fit_firth_scaled)
# 標準化されたオッズ比
exp(coef(fit_firth_scaled))
# 標準化されたオッズ比の信頼区間
exp(confint(fit_firth_scaled))
```

# プロビット回帰分析

ロジスティック回帰分析と同様に，従属変数が2値変数である場合に適用される分析手法としてプロビット回帰分析がある．

:::ref
<details>
<summary>プロビット回帰分析とは</summary>
ロジスティック回帰分析がロジスティック関数を用いて確率を表現するのに対して，プロビット回帰分析は累積正規分布関数を用いて確率を表現する．

$$
P_{y=1} = \Phi(a+b\times x)
=\int_{-\infty}^{a+b\times x} \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}z^2}dz
$$
累積正規分布関数を図示すると以下のように，ロジスティック関数と同様に0から1の間の値を取ることが分かる．

```{r echo=FALSE}
x <- seq(-10, 10, 0.1)
y <- pnorm(x)
plot(x, y, type = "l", xlab = "x", ylab = "y")
```
</details>
:::

ロジスティック回帰分析とプロビット回帰分析のどちらを選択するかは，研究目的やデータの性質によって異なる．一般にマーケティング分野などの心理学や行動科学を基盤とする分野ではロジスティック回帰分析の方が，経済や金融分野ではプロビット回帰分析が用いられる傾向があるようである．ただ，サンプル数が十分に大きい場合には，ロジスティック回帰分析とプロビット回帰分析の結果はほぼ同じになるため，どちらを選択しても問題ない．

Rでプロビット回帰分析を行う場合には，`glm`関数の`family`引数に`binomial(link = "probit")`を指定する．

```{r}
fit_probit <- glm(購入 ~ 性別 + 年齢 + 時間帯, data = data, family = binomial(link = "probit"))
summary(fit_probit)
```


## 完全分離の問題
プロビット回帰分析においても「glm.fit: 数値的に 0 か 1 である確率が生じました」という警告が出ることがある．実際に上記の例ではこの警告が出てきている．
この警告への対応は，ロジスティック回帰分析の時と同じく，Firthのバイアス補正法を適用することである．
ロジスティック回帰分析とは異なり，プロビット回帰分析においては`logistf`パッケージを用いることはできないため，`brglm2`パッケージを用いる方法を示す．

```{r}
# インストールしたパッケージの読み込み
library(brglm2)
#普通にglmを実行
fit_probit <- glm(購入 ~ 1+性別 + 年齢 + 時間帯, data = data, family=binomial(link = "probit"))
# バイアス低減法を適用
fit_probit_brglm2 <- update(fit_probit, method="brglmFit")
#結果の出力
summary(fit_probit_brglm2)
```



## 結果の報告

プロビット回帰分析の結果もロジスティック回帰分析と同様に，各説明変数の回帰係数は直感的には理解しにくいので理解しやすい数値に変換して報告するのが一般的である．ロジスティック回帰分析の場合はロジット変換がから容易にオッズ比を算出することができるため，オッズ比の報告が行われるが，プロビット回帰分析の場合にはオッズ比の代わりに**平均限界効果(Average Marginal Effect)**が報告されることが多い．マージナル効果は，説明変数が1単位変化した際に目的変数が1となる確率$P$がどの程度変化するかを示す指標である．


:::ref
<details>
<summary>平均限界効果の算出式</summary>
平均限界効果は，説明変数$x$が1単位変化した際の目的変数$y$の平均変化量を示す指標であり，以下の式で計算される．
$$
AME = \frac{1}{n}\sum_{i=1}^{n}\frac{\partial P(y=1|x)}{\partial x_i}
$$
この式は，説明変数$x$が1単位変化した際の目的変数$y$の平均変化量を示している．
</details>
:::

Rで平均限界効果を算出するためには，`margins`パッケージを用いるとよい（予め`logistf`パッケージをインストールしておく必要がある）．

```{r}
# インストールしたパッケージの読み込み
library(margins)
# 平均限界効果の算出
marginal_effects <- margins(fit_probit_brglm2)
# 結果の出力
summary(marginal_effects)
```
結果のAMEが各説明変数の平均限界効果を示している．SEは標準誤差，Zは検定統計量であり，pは有意確率を示している．lowerとupperは95%信頼区間の下限と上限を示している．
要するに，時間帯が1時間変化すると購入確率が1.6\%増加する，また年齢は1歳上がると購入確率は1\%増加する，といったように解釈することができる．


# ポアソン回帰分析

