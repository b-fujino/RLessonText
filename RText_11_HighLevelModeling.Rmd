---
title: "因果関係の高度な分析"
author: "藤野秀則"
date: 
  初稿日:"2024-10-08"
  更新日:`r Sys.Date()`
output:
  html_document: 
    toc: true
    toc_depth: 4
    toc_float: true
    number_section: true
    fig_width: 8
    css: ./style.css
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

因果関係を検証する分析として，これまでに回帰分析・重回帰分析と分散分析を説明した．ただ，これまで紹介してきた手法は基本ではあるものの，最近の統計学に関する理論研究の進展により，それらの基本的で伝統的（Conventional）な手法にはいくつかの問題が指摘されるようになっており，それらの問題点をクリアできるような分析方法が提案されてきている．

ここではそれらについての解説とRでの実施方法を説明していく．

# ダミー変数を用いた回帰分析

# ロジスティック回帰分析

ロジスティック回帰分析は，従属変数が二値変数（0または1）である場合に適用される．例えば，ある商品を購入するかどうか（購入する場合は1，しない場合は0）を予測する場合などに用いられる．

:::ref
数学的な説明をすると，普通の回帰分析（特に単回帰分析）では，「目的変数$y$と説明変数$x$との関係は$y=a+b\times x$という直線（1次関数）の関係にある」という仮定を置いて，Xに対するYの実測値と式から予測されたYの値の誤差がデータ全体で最も小さくなるように$a$と$b$を求める，ということをしていた．
これに対してロジスティック回帰分析では，まず目的変数$y$は0か1という2値であるという前提のもとで，あるXが与えられたときにyが1である確率$P$と説明変数$x$との関係は以下に示すようなロジスティック関数によって表現される，という仮定を置いて，その関数のパラメータをデータから推定する．

$$
P_{y=1} = \frac{1}{1+e^{-(a+b\times x)}}
$$

この式の中で，$e$は自然対数の底，もしくはネイピア数（2.71828...）と呼ばれる．

このロジスティック関数の特徴は，$x$がどんな値であっても$P$は0から1の間の値を取ることである．
この関数の形状は以下のようになる．

```{r echo=FALSE}
x <- seq(-10, 10, 0.1)
y <- 1/(1+exp(-x))
plot(x, y, type = "l", xlab = "x", ylab = "y")
```

つまり，$x=0$を境に$x$が増加すればするほど，$P$は1に近づく．つまり，目的変数$y$は1である確率が高まる(=$y$が0である確率が低まる）．逆に$x$が減少すればするほど，$P$は0に近づく．つまり，目的変数$y$は1である確率が低まる（=$y$が0である確率が高まる）．

こうしたことから，ロジスティック関数を当てはめることによって，あるxが充てられたときに，目的変数が0か1のいずれの値を取る可能性が高のかを予測することができるようになる．

なお，普通の回帰分析では目的変数$y$は連続変数であるということに加えて，yの値の確率分布は正規分布であ（言い換えれば，あるxが与えられた時のyの値がどういう値になるかは正規分布で表現される確率分布に従っている）るという仮定を置いている．一方，ロジスティック回帰分析では目的変数$y$は0，1の2値変数であるため，$y$が0,1のいずれの値になるか（つまり$y$の確率分布）は2項分布に従っているという仮定が置かれる．
:::

:::ref
ロジスティック回帰分析におけるモデル式は上記の通り，ロジスティック関数によって表記されるが，この関数を線形回帰分析の式に変換することもできる．



\begin{align}
P &= \frac{1}{1+e^{-(a+b\times x)}} \\

\frac{1}{P} &= 1+e^{-(a+b\times x)} \\

\frac{1}{P}-1 &= e^{-(a+b\times x)} \\

\frac{1-P}{P} &= e^{-(a+b\times x)} \\

\log{\left(\frac{1-P}{P}\right)} &= -(a+b\times x) \\

\therefore \ \ \log{\left(\frac{P}{1-P}\right)} &= a+b\times x
\end{align}

このような変換をロジット変換と呼ぶ．このロジット変換を行うと，左辺は対数オッズ（log odds）と呼ばれる．対数オッズは，ある事象が起こる確率と起こらない確率の比率を対数変換したものであり，この値が正の値を取れば取るほど，その事象が起こる確率が高まることを示す．
:::


:::practice
[このデータ](./Example_11_Logistic.csv)は，ある店舗のPOSデータからランダムサンプリングした来店者500人分の性別（0:男，1:女），年齢帯（10～70まで10年刻み），来店時間帯（9時～22時まで1時間刻み）と，その人がとある新製品を購入したかどうか（0:購入していない，1:購入した）を記録したデータである．このデータをもとに，ある来店客の性別・年齢帯・来店時間帯からその客が新製品を買うか買わないかを予測する式を立てよ．

```{r include=FALSE}
library(tidyverse)
set.seed(123)
Sex <- sample(0:1, 500, replace = TRUE)  
Age <- sample(10:79, 500, replace = TRUE) %/%10 * 10

# 小さな山（10時台）：平均10, 標準偏差1の正規分布からサンプリング
base_customers <- sample(9:22, 150, replace = TRUE) 
morning_customers <- round(rnorm(50, mean = 10, sd = 1),0)
# 大きな山（17時台）：平均17, 標準偏差1の正規分布からサンプリング
evening_customers <- round(rnorm(300, mean = 17, sd = 2),0)
# 両方の分布から生成されたデータを結合
Time <- c(base_customers, morning_customers, evening_customers)
# 時間帯を9時から22時の範囲に収めるために四捨五入し、範囲外を9-22に修正
Time <- ifelse(Time < 9, 9, ifelse(Time >= 22, 22, Time))

# したかどうか
Buy <- 1/(1+exp(-(0.4*Sex + 0.21*Age + 0.4*Time + 2*rnorm(500, 0, 0.5)))) 
Buy <- ifelse(Buy > mean(Buy), 1, 0)

data <- data.frame(
  性別 = Sex,
  年齢 = Age,
  時間帯 = Time,
  購入 = Buy
)

write.csv(data, file = "Example_11_Logistic.csv", row.names = FALSE)
```

:::

Rでロジスティック回帰分析を行うためには，`glm`関数を用いる．
第1引数には，`formula`関数を用いて，`目的変数 ~ 説明変数1 + 説明変数2 + ...`という形式で指定する．
第2引数には，`data`引数にデータフレームを指定する．
第3引数には，`family`引数に`binomial`を指定する．

```{r}
data <- read.csv("Example_11_Logistic.csv")
model <- glm(購入 ~ 性別 + 年齢 + 時間帯, data = data, family = binomial)
summary(model)
```

この結果から，この新製品を購入するかどうかを予測する式は以下のようになる．

$$
P = \frac{1}{1+e^{-(-14.7+0.323 \times \text{性別} + 0.398 \times \text{年齢} + 0.647 \times \text{時間帯})}}
$$ 


$$
\log \left( \frac{p}{1-p} \right) = -14.7+0.323 \times \text{性別} + 0.398 \times \text{年齢} + 0.647 \times \text{時間帯}
$$



