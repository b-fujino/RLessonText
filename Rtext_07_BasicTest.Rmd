---
title: "基本的な検定"
author: "藤野秀則,"
date: 
  初版日:2024-05-02
  更新日:`r Sys.Date()`
output:
  html_document: 
    toc: true
    toc_depth: 4
    toc_float: true
    number_section: true
    fig_width: 8
    css: ./style.css

  # html_notebook:
  #   toc: true
  #   toc_depth: 3
  #   toc_float: true
  #   number_section: true
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```


# 平均の比較

## 比較の原理

2つのグループの間で平均を比較したい場合にはt検定というものを行う．これは厳密には**「2つのグループは元々は同じ母集団から抽出されたサンプルである」**という仮説（これを**帰無仮説**と呼ぶ）の元で，両グループの平均値の間に有意といえるほどの差があるかどうかを検定する手法である．

「元々同じ母集団である」という仮説の元では，理想的には両群の平均値は一致する，すなわち差は0になるはずである．実際にはデータにはばらつきは付きものなので，完全に0となることはないだろうが，差の値は0に近い値になる確率は高いだろし，0から遠い値になる確率は低いだろう．

そこで，実際に2つのグループのデータから、それぞれの平均値の差を求めたうえで，「2つのグループは同じ母集団から抽出されたサンプルである」という仮説のもとで，そのような差が出てくる確率はいくらであったかを算出する，というのがt検定の数学的な中身である．

そして，その確率が0.05，すなわち5%未満であったならば「2つは同じ母集団から抽出されたサンプルである」という仮定のもとでは極めて珍しい（発生確率が5%未満でしかない）値が出た，ということになる．ここで解釈の転換をして，「そんな珍しい値が出るなんてそうそうあることではない．そもそも元の仮説が誤っていたのではないか」と考える．つまり，「2つは同じ母集団から抽出されたサンプルである」という仮説を否定するのである．この仮説を否定するということは，「2つのグループは互いに性質の異なる（それゆえ母平均も異なる）母集団から抽出されたサンプルである」という仮説を支持する，ということである．こうして，2つのグループには「母集団のレベルで差がある」と主張するのがt検定である．

## t検定の方法（基本）

Rでt検定を行うには`t.test()`関数を用いる．この関数は、[平均の信頼区間](RText_04_DescriptiveStatistics.html#平均値の区間推定)で用いた関数であるが、本来は名前のとおりt検定を行う関数である．引数は以下の通りである．

- 第1引数：比較先のベクトルデータ
- 第2引数：比較元のベクトルデータ
- 第3引数`alternative`（省略可）:「両側検定」を行うのか「片側検定」を行うの指定．デフォルトでは両側検定となっていおり，通常は両側検定を行うのが一般的であるため，省略するのが一般的である．特に片側検定にしたい場合には，比較先の平均が比較元の平均より「高い」ということを検証したい場合には "greater"，「低い」ということを検証したい "less"を指定する．

．いずれも**ベクトルデータ**で与える必要がある点に注意が必要である．




:::ref
<details>
<summary>両側検定と片側検定</summary>
両側検定は「データAの平均がデータBの平均に比べて有意に大きい」「データAの平均がデータBの平均に比べて有意に小さい」「両群に差があるとは言えない」という3つのいずれになるかを知りたい場合に用いる．

一方，片側検定では，事前に「データAの方がデータBに比べて大きい（小さい）はずである」ということが理論的に予想されている中で，「有意に大きい（小さい）」もしくは「大きい（小さい）といえない」という2つのいずれになるかを知りたい場合に用いる．

すなわち，片側検定では逆の結論は全く想定していないことになる．数学的には，両側検定の時に算出される確率（P値）はは片側検定のときのP値の2倍となる．すなわち，両側検定にした場合，有意になりにくくなる（5\%を上回りやすくなる）．このため，「有意になってほしい」という思いが強いと，片側検定にしたくなるが，片側検定をする場合，それを選択した理由をきちんと述べねばならない．

一般的には両側検定を用いることが多く，`t.test()`に限らず，Rで行う統計分析で有意検定を行っているものは**両側検定がデフォルトで実行される．**
</details>
:::

:::practice
ある農作物に与える肥料を新しく試作した．その効果を確かめるために，新しい肥料を与えた畝と通常の肥料を与えた畝を20ずつ用意し，それぞれの収穫量を測定した．その結果，次のようなデータ（[リンク](./practice/example_ttest.csv)）が得られた．このデータから新しい肥料を使用した場合に収穫量が向上するのかどうかを検証せよ．
:::

```{R eval=FALSE, include=FALSE}
# 再現性を確保するために乱数シードを設定
set.seed(42)

# データの個数
num_samples <- 20

# 通常の肥料を使用した場合の収穫量（平均50，標準偏差5）
normal_fertilizer_yield <- round(rnorm(num_samples, mean = 45, sd = 5),2)

# 新しい肥料を使用した場合の収穫量（平均55，標準偏差5）
new_fertilizer_yield <- round(rnorm(num_samples, mean = 55, sd = 5),2)

# データフレームの作成
data <- tibble(
  通常の肥料を使用 = normal_fertilizer_yield,
  新しい肥料を使用 = new_fertilizer_yield
)

# CSVファイルにデータを保存
write_csv(data, "./practice/example_07_ttest.csv")

```

この例題の場合，t検定を行うコードは以下の通りとなる．
```{r}
mydata_ttest <- read.csv( # データ読み込み オブジェクト名は自由につけてよい
# データは以下の設定ではpracticeというフォルダに入っているコトになっているが，
# 特にそうしたフォルダに入れていない場合には ./example_ttest.csv とすればよい．
  "./practice/example_ttest.csv", 
  header=T, 
  fileEncoding = "UTF8"
)

# データの内容を確認
head(mydata_ttest)
# すべてのデータを見てみたければ
# 右上ペインのEvironmentのmydataをクリックするか，
# 以下のコマンドを実行．
# view(mydata)

# それぞれのベクトルデータを取得
新肥料 <- mydata_ttest$新しい肥料を使用
旧肥料 <- mydata_ttest$通常の肥料を使用


t.test(新肥料, 旧肥料)#Alternativeは省略　

```

2行目の`p-value = 0.0002922`という箇所が結果を示す箇所であり，また最後の
```{}
mean of x mean of y 
   53.645    45.960 
```
は，それぞれのデータの平均値である．

このデータではP値は0.05を下回ってり，「二つのグループは同じ母集団から抽出されたサンプルである」という帰無仮説を棄却された．すなわち，両者の平均は有意な違いがあるという結論となり，新しい肥料を用いることで収穫量の向上が望めることが示されたこととなる．

## 対応関係のあるデータでのt検定


対応関係とは，例えば2つのデータが「同じ人の1回目の測定と2回目の測定」というように，「同じサンプルから条件を変えて取得したデータ」である場合には，データの中で対応関係（ペア関係）が成立する．
このようなデータの場合には，**第4引数として, `paired = TRUE`というオプションを設定する必要がある**．

対応関係は，データの並びによってとられる．すなわち，

データ1の1つ目のデータ⇔データ2の1つ目のデータ<br/>
データ1の2つ目のデータ⇔データ2の2つ目のデータ<br/>
データ1の3つ目のデータ⇔データ2の3つ目のデータ<br/>
・・・<br/>

という対応関係がとられる．

なお，対応関係のあるデータでは，当然ながら二つのデータの点数は「同じ」であることが前提となる．
従って，`paired=TRUE`の設定をしている時に，一方のデータの中に`NA`が1つでも含まれていた場合には，`t.test()`はエラーを返してくる．
これを防ぐためには，さらに第5引数**na.rm=TRUEのオプション設定を行う**．
このオプションを設定していた場合，**一方のデータに`NA`が含まれていた場合，`NA`に対応したもう一方の値も除去される**．



:::practice
15人の協力者に，新しく試作した食パンと従来の食パンの食べ比べをしてもらい，おいしさを10段階で評価してもらったところ，次のようなデータ（[リンク](./practice/example_ttest_paired.csv)）が得られた．このデータをもとに，試作品と従来品とで美味しさの違いがあるのかを検証せよ．
:::

```{r eval=FALSE, include=FALSE}
# 再現性を確保するために乱数シードを設定
set.seed(42)

# データの個数
num_samples <- 15

# 従来の食パンの評価（平均6，標準偏差1.5）
traditional_bread_scores <- round(rnorm(num_samples, mean = 6, sd = 1.5),0)

# 新しい食パンの評価（平均7.5，標準偏差1.5）
new_bread_scores <- round(rnorm(num_samples, mean = 7.5, sd = 1.5),0)

# データフレームの作成
data <- tibble(
  従来品 = traditional_bread_scores,
  試作品 = new_bread_scores
)

# CSVファイルにデータを保存
write_csv(data, "./practice/example_07_ttest_paired.csv")
```

この例題の場合，**同じ人に対してデータを取っているため，二つのベクトルの間には対応関係が存在する**．このため，`paired`の設定が必要になる．は以下の通りとなる．

```{r}
mydata_ttest_paired <- read.csv(
  "./practice/example_ttest_paired.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み
# もしデータの内容を確認したければ，右上ペインのEvironmentのmydataをクリックするか，以下のコマンドを実行．
# view(mydata)

t.test(mydata_ttest_paired$従来品, mydata_ttest_paired$試作品, paired=TRUE, na.rm=T)

```
今回のデータの場合，p値は0.8123となっており，0.05を大きく上回っており，試作品と従来品とでおいしさに有意な差はない，という結論となる．
また，`paired`の設定をしたので，表題も`Paired t-test`となり，最後の結果も両群の平均値ではなく，群間の差のみが算出される．






## ロング形式データでのt検定

ロング形式のデータの場合，`filter()`を使って，分析に掛けるベクトルデータをそれぞれ取り出せば，基本のt検定の方法で分析ができるが，いちいち個別にベクトルデータを取りださなくても，**測定変数と属性変数を`~`（チルダ）で結んだ「式」**を`t.test()`関数の第1引数に与えることでも分析ができる．なお，**属性変数のデータは要因型**である必要がある．この場合，第2引数にはそれぞれの変数を含んだデータフレームのオブジェクト名を与える．

以下は例題1のデータをロング形式に変換したうえで，式形式でのt検定を行う例である．

```{r}
library(tidyverse) # pivot_longer関数を使うにはtidyverseを読み込む必要がある

# ロング形式のデータを作成
long_data <- pivot_longer(
  mydata_ttest,
  cols=colnames(mydata_ttest),
  names_to = "肥料",
  values_to= "収穫量" #測定変数に与える列名
)

# 肥料列を要因型に変換
long_data$肥料 <- as.factor(long_data$肥料)

# 内容確認
summary(long_data)

#t検定
t.test(収穫量~肥料, long_data)
```


<!-- (以下，2024.10.9追記) -->
「対応あり」データ(paired=TRUEとなるデータ）がロング形式のデータとなっている場合に，R 4.4.1（2024.10.9時点の最新，Posit Cloudはこちら）では，上記の例のように`式, data`形式を与える形での分析はできない．対応ありデータの場合には，以下の例のようにそれぞれのデータを取り出してt.testにかける必要がある．
<!-- （R 4.3.3であれば(式, data)形式でもpaired=TRUEの設定が可能）． -->

```{r error=TRUE}
## ロング形式のデータを作成
long_data_paired <- pivot_longer(
  mydata_ttest_paired,
  cols=colnames(mydata_ttest_paired),
  names_to = "食パン",
  values_to= "評価" #測定変数に与える列名
)

# 確認
long_data_paired$食パン <- as.factor(long_data_paired$食パン)
summary(long_data_paired)

# 以下の形式だとエラーになる．
t.test(評価~食パン, long_data_paired, paired=TRUE, na.rm=TRUE) 
 
# ロングデータからの食パンごとのデータを取り出し
data1 <- filter(long_data_paired, 食パン=="従来品")
data2 <- filter(long_data_paired, 食パン=="試作品")


# t検定
t.test(data1$評価, data2$評価, paired=TRUE)


```



:::ref
<details>
<summary><a name = "t検定の種類"/>t検定の種類</summary>
t検定には大きく以下の3つの種類がある．

- 対応するデータでのt検定
- Studentのt検定
- Welchのt検定

ExcelやGoogle Spread SheetでT検定を行う場合も，「検定の種類」という項目があるが，これは上記の3つのどれを行うかを選択するものである．

対応するデータでのt検定は，すでに説明した通り，同じサンプルから取得したデータを比較する場合に用いる．

一方，StudentのT検定とWelchのT検定はいずれも「対応のないデータ」を比較する場合に用いるが，両者の違いとして，比較先・比較元の両データについて「母集団の分散が等しいとする仮定（等分散性の仮定）を立てるか，立てないか」という点が異なる．

StudentのT検定は，両データの母集団の分散が等しいと仮定して行う検定であるのに対して，WelchのT検定は，母集団の分散が等しいという仮定を立てないで行う検定である．

一昔前は，以下で述べる[分散の比較（F検定）](#分散の比較)を行い，その結果に基づいてStudentのT検定かWelchのT検定かを選択することが一般的であった．すなわち，F検定の結果，「5%有意で分散が違っている」という結果が出ればWelchのT検定を使い，有意でなければStudentのT検定を行うということが行われていた．

しかし，こうした選択方法は最近では否定的に捉えられるようになっている．その理由に，「有意検定は『等しい』ことの保証にはならない」という点と，さらに以下で述べる[検定の多重性問題](#検定の多重性問題)によるからである．

特に1点目について，F検定の結果，「有意確率が5%を下回った」という結果は「分散は等しくない」ということの強い根拠となる．しかしその逆である「有意確率が5%を上回った」という結果は，「分散は等しい」ということの強い根拠とはならない．あくまで**「分散は等しい」という帰無仮説は棄却されなかった**というだけに過ぎず，「本当は両者の間の分散は違っている」という可能性が残されているのである．こうしたことから，F検定の結果に基づいて，Wlechの検定を選択することは正しい選択であると言えるが，Studentの検定を選択することは誤った選択である可能性が残されてしまう．

さらに，Welchの検定では，たとえ実際には分散が等しかった場合でも，かなり正確な結果を返してくることが様々なパターンでのシミュレーションの結果から明らかになっている[[1]](#Paper)．

このため，最近では**「分散が等しいかどうか」を気にせずにWelchの検定を使うことが推奨されるようになっている**．

<a name="Paper">[1] Delacre, M., et al (2017). Why Psychologists Should by Default Use
Welch’s t-test Instead of Student’s t-test. International Review of
Social Psychology, 30(1), 92–101, DOI: https://doi.org/10.5334/irsp.82</a>

</details>
:::

## t検定の結果の報告方法
t検定の結果を報告する際には棒グラフを用いるのが一般的である（平均なので箱ひげ図は用いない）．二つの群の平均と標準偏差を棒グラフで表現したうえで，角傘（ブラケットと呼ぶ）をつけてp値を記載する．

<a name="推測統計量"/>

:::ref
t検定は，あくまでそのデータの違いを見ているのではなく，そのデータから推定される母集団に違いがあるかを検証するものである．このため，t検定の結果を報告する際に用いる統計量は，推測統計量となる．このことはt検定だけに限らず，あらゆる分析にあてはまる．今後解説していくあらゆる分析は得られているデータを基に推定される母集団の比較をしたり，母集団間の関係性を分析したりするものである．このため，**今後の分析の中で出てくる平均や標準偏差は全て基本的に推測統計量となる**．
:::


具体的にggplotを使って，先の2つの例題の結果を棒グラフで表記してみよう．まずは，[こちら](./RText_06_ggplot2_basicUsage.html#棒グラフ)のコードを参考に棒グラフを作成する．まずは例題1．
```{r}
library(ggplot2) # ggplotを使うためにはまずこのライブライを読み込んでおく必要がある

#まずは両群の平均と標準偏差を算出する．
mymean_new <- mean(mydata_ttest$新しい肥料を使用)
mymean_old <- mean(mydata_ttest$通常の肥料を使用)
mysd_new <- sd(mydata_ttest$新しい肥料を使用)
mysd_old <- sd(mydata_ttest$通常の肥料を使用)

mydf <- data.frame(
  条件=c("新しい肥料を使用", "通常の肥料を使用"),
  収穫量=c(mymean_new, mymean_old),
  標準偏差=c(mysd_new, mysd_old)
)

# ggplotで棒グラフを表示　
g <- ggplot(data=mydf)+ 
  geom_bar(aes(x=条件, y=収穫量, fill=条件), stat="identity")+
  geom_errorbar(aes(x=条件, ymin=収穫量-標準偏差, ymax=収穫量+標準偏差, width=0.1))
plot(g)
```

続いて，このグラフにブラケットをつけてp値を記載する．ブラケットをつけるためには，`annotate()`関数を用いて線分を描画する．この関数は第1引数として`"segment"`（線分の意味）を指定し，第2～４引数として始点と終点の座標を指定すると，その間に線分を描画する関数である．これを組み合わせてブラケットを描画する．x軸方向は「新しい肥料を使用」「通常の肥料を使用」というように数値ではなくラベルとなっているが，内部では座標として，それぞれ1，2とされているので，これを利用してブラケットを描画する．y座標については，エラーバーと干渉しないような値を設定してやる．以下では`y＝61, yend=64`としているが，別にこの値でなくてもよい．

```{r}
#エラーバーの上に実線を引く
g <- g + 
  annotate("segment",x=1, xend=1, y=61, yend=64)+
  annotate("segment",x=1, xend=2, y=64, yend=64)+
  annotate("segment",x=2, xend=2, y=61, yend=64)

plot(g)
```

さらに，これにp値を与える．これも`annotate()`関数を用いる．第1引数で`"text"`と指定して，`x`，`y`引数で座標（記載する文字列の中心位置）を指定し，`label`引数で表示する文字列を，`size`引数で文字の大きさを指定する．

```{r}
# 各傘の上に
g <- g+annotate("text",x=1.5, y=66, label="p=0.0002922, ***", size=3)
plot(g)
```

p値にはアスタリスクをつけるのが一般的である．アスタリスク（\*）の数はp値の大小に応じて変わる．**p値が0.05未満であれば1つ，0.01未満であれば2つ，0.001未満であれば3つとする**．

逆に有意でなかった場合には，P値を表記するだけで何も記載しないか，あるいは，`n.s.`と記載する．これは`not significant`の略であり，「有意でない」という意味である（さらに[多重比較](#多重比較)を行うケースでは有意でないものについてはブラケットも含め何も表記しないのが一般的である）．

また，上記の例のようにP値が0.000を下回っている場合には，桁を省略して，`P<0.001`と表記することもある．さらに，論文や報告書などでP値を文章中に明記している場合には，図ではP値を省略して，アスタリスクだけを記載することもある．

例題2の方でも同様に棒グラフを作成してみよう．今度は描画関数をすべてまとめて記載する．
```{r}
#まずは両群の平均と標準偏差を算出する．
mymean_new <- mean(mydata_ttest_paired$試作品)
mymean_old <- mean(mydata_ttest_paired$従来品)
mysd_new <- sd(mydata_ttest_paired$試作品)
mysd_old <- sd(mydata_ttest_paired$従来品)

# データフレームの作成
mydf <- data.frame(
  条件=c("試作品", "従来品"),
  おいしさ=c(mymean_new, mymean_old),
  標準偏差=c(mysd_new, mysd_old)
)

# ggplotで棒グラフを表示
g<- ggplot(data=mydf)+ 
  geom_bar(aes(x=条件, y=おいしさ, fill=条件), stat="identity")+
  geom_errorbar(aes(x=条件, ymin=おいしさ-標準偏差, ymax=おいしさ+標準偏差, width=0.1))+
  annotate("segment",x=1, xend=1, y=9, yend=10)+
  annotate("segment",x=1, xend=2, y=10, yend=10)+
  annotate("segment",x=2, xend=2, y=9, yend=10)+
  annotate("text",x=1.5, y=10.5, label="p=0.8123, n.s.", size=5)
plot(g)

```



なお，ロング型のデータの場合には，[こちら](./RText_04_DescriptiveStatistics.html#グループごとの統計量の算出)で説明した通り，平均や標準偏差は`aggregate()`関数を用いて算出するとよい．以下これらを使って棒グラフを表示させる．

```{r}
# 平均値の算出
平均<-aggregate(収穫量~肥料, long_data, mean)
# 標準偏差の算出
標準偏差<-aggregate(収穫量~肥料, long_data, sd)

#データフレームの作成
mydf <- data.frame(
  条件=平均$肥料,
  収穫量=平均$収穫量,
  標準偏差=標準偏差$収穫量
)

# ggplotで棒グラフを表示
g<- ggplot(data=mydf)+
  geom_bar(aes(x=条件, y=収穫量, fill=条件), stat="identity")+
  geom_errorbar(aes(x=条件, ymin=収穫量-標準偏差, ymax=収穫量+標準偏差, width=0.1))+
  annotate("segment",x=1, xend=1, y=61, yend=64)+
  annotate("segment",x=1, xend=2, y=64, yend=64)+
  annotate("segment",x=2, xend=2, y=61, yend=64)+
  annotate("text",x=1.5, y=66, label="p=0.0002922, ***", size=4)
plot(g)
```


:::work
ある自治体の高校生を対象に朝食摂取と成績の関係を明らかにするために調査をおこない，このような[データ](./practice/07_work_1.csv)を取得した．この調査では，調査日（抜き打ち実施）に朝食を食べているかどうかと，4限目の授業で実施した数学のテストの得点がデータとして取得されている．このデータについて，以下の課題を実施せよ．

1. このデータの冒頭6行分をhead()を用いて確認し，このデータがワイド形式かロング形式か確認せよ．
1. 摂取群と欠食群のそれぞれの平均と標準偏差（[こちら](#推測統計量)で述べている通り推測統計量でよい）を算出するとともに，それらを棒グラフで示せ．棒グラフにはエラーバーも付与すること．
1. 朝食を食べている人と食べていない人とで数学のテストの得点に有意な差があるかどうかを検証せよ．
1. 先に描いた棒グラフ上にt検定の結果を示すブラケットを書き入れよ．

```{r include =F}
set.seed(42)

# データの個数
num_samples <- 4000
result <- sample(c("摂取", "欠食"), num_samples, replace = TRUE, prob = c(0.72, 0.38))
score <- round(rnorm(num_samples, mean = 50, sd = 10),0)

library(tidyverse)
weight <- ifelse(result == "摂取", 3, 0)
data <- tibble(
  朝食 = result,
  得点 = score+weight
)

write.csv(data, "./practice/07_work_1.csv",row.names=FALSE)
```


:::

:::work
あるショコラティエで，新しいチョコレートの試作に取り組んでいる．同じチョコレートでも，どのような形に成形するかで，味の評価が変わるのではないかと考え，店に来店したお客さん50人にそれぞれを食べてもらい，おいしさを10段階で評価してもらい，次のような[データ](./practice/07_work_2.csv)を取得した．このデータについて，以下の課題を実施せよ．

1. このデータの冒頭6行分をhead()を用いて確認し，このデータがワイド形式かロング形式か確認せよ．
1. 形状Aと形状Bのそれぞれの平均と標準偏差を算出するとともに，それらを棒グラフで示せ．棒グラフにはエラーバーも付与すること．
1. 形状Aと形状Bとでおいしさに有意な差があるかどうかを検証せよ．
1. 先に描いた棒グラフ上にt検定の結果を示すブラケットとt検定の結果えられた有意確率を書き入れよ．

```{r include =F}
set.seed(23)

# データの個数
library(truncnorm)
num_samples <- 50
score_A <- round(rtruncnorm(num_samples, a=0, b=10, mean = 6, sd = 1.5),0)
score_B <- round(rtruncnorm(num_samples, a=0, b=10, mean = 7, sd = 2.5),0)

data <- tibble(
  No. = 1:num_samples,
  形状A = score_A,
  形状B = score_B
)

write.csv(data, "./practice/07_work_2.csv",row.names=FALSE)
```

:::


# 分散の比較

先ほどは2つのグループの間での平均の比較，すなわち「2つのグループの間で平均値の差が意味のある差なのか誤差の範囲に収まる差なのか」を検証する方法について説明した．次に，2つのグループの間で「ばらつき」，すなわち分散に違いがあるのかどうかを検定する方法（F検定）について説明する．


:::ref
<details>
<summary>分散比</summary>
実際にはRの中での処理なので，意識することはないが，分散の場合には「差」をではなく，「比率」（すなわち割り算をする）で比較をしている．すなわち，2つのグループの分散の比率を求め，それが1（すなわち等しい）かどうかを検定することになる．

平均の場合には差であったものが，なぜ分散では比を取るのかというと，分散はそれぞれのサンプルの値と平均との差の**2乗**から算出されるため，同じ程度の有意性があったとしても，分散が大きいもの同士を比較している場合には差は大きくなるし，分散が小さいもの同士を比較していると差は小さくなる，というように差の大きさを絶対的な物差しで評価することができないためである．
</details>
:::

分散の比較における**帰無仮説は「2つの群の母集団の分散は等しい」**となる．この帰無仮説が棄却された場合，すなわちP値が有意水準を下回った場合，「2つの群の母集団の分散は等しくない」と結論づけることができる．

:::ref
分散の比較においては，「対応のあるデータ」についての検定は行わない．その理由として，対応のあるデータでは，「群の分散」よりも「それぞれのペアごとの差の平均」が重要（差の平均の母数が0となるか）であるためであり，各群を別個に捉えて分散を比較することに意味はないからである．
:::


## F検定の方法（基本）
F検定は，Rの`var.test()`関数を用いて行う．この関数の基本的な引数は以下の通りである．

- 第1引数：比較先のベクトルデータ
- 第2引数：比較元のベクトルデータ

第1引数と第2引数に比較したい2つのグループのデータを与える．この関数は，t検定と同様に「2つのグループは同じ母集団から抽出されたサンプルである」という仮説の元で，2つのグループの分散の比率が1であるかどうかを検定する．

:::practice
ある製品の製造工程を変更したところ，製品の重量にばらつきが生じた．このばらつきが工程変更の影響によるものなのか，単なる偶然によるものなのかを検証するために，工程変更前と工程変更後の製品の重量を測定した．その結果，次のようなデータ（[リンク](./practice/example_vartest.csv)）が得られた．このデータから工程変更によるばらつきの変化があるのかを検証せよ．
:::

```{r include=FALSE}
#./practice/example_vartest.csvの作成
set.seed(42)
num_samples <- 20
before_change <- round(rnorm(num_samples, mean = 1000, sd = 5),2)
after_change <- round(rnorm(num_samples, mean = 1000, sd = 10),2)
data <- tibble(
  工程変更前 = before_change,
  工程変更後 = after_change
)

write_csv(data, "./practice/example_07_vartest.csv")
```

Rのスクリプトは以下の通りとなる．

```{r}
mydata_vartest <- read.csv(
  "./practice/example_vartest.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

変更前 <- mydata_vartest$工程変更前
変更後 <- mydata_vartest$工程変更後

# それぞれの分散を確認しておく
var(変更前)
var(変更後)

# F検定
var.test(変更後,変更前 )

```

この結果から，P値が0.027となっており，5％の有意水準を下回っているため，工程変更によって製品の重量のばらつきに有意な変化が生じたと結論づけることができる．


## ロング形式のデータでのF検定

ｔ検定の時と同様に，ロング形式のデータの場合には`測定変数~要因変数, データ`の形でも検定を行うことができる．以下にその例を示す．

```{r}
#ワイド形式からロング形式に変換
long_data_vartest <- pivot_longer(
  mydata_vartest,
  cols=colnames(mydata_vartest)[],
  names_to = "工程",
  values_to= "重量" #測定変数に与える列名
) 

# 工程を要因型（要因型）に変換
long_data_vartest$工程 <- as.factor(long_data_vartest$工程)

# F検定の実施
var.test(重量~工程, long_data_vartest)
```

## F検定の結果の報告方法
F検定の結果を報告する際には，一般には棒グラフを用いることは少ない．F検定の結果は，P値が有意水準を下回っているかどうかを確認するだけでよい．P値が有意水準を下回っている場合には「2つの群の分散は5%の有意水準のもとで有意な違いがある（F(`df1`, `df2`)=`F-Value`, P=`value`）」と記載する．`df1`と`df2`はそれぞれの2つの群の自由度（各群のサンプル数―1）を示し，`F-Value`はF値を示す．

例えば，上の例題の場合には，「工程変更前と工程変更後の製品の重量の分散に有意な違いがあることが示された（F(19, 19)=2.860, P=0.027）．」と記載する．

:::work
ある製品メーカでは公称重量70gの金属部品を製造しているが，製造工程の中でどうしても多少のばらつきが発生してしまうため，69.950g～70.049gまでを許容範囲とし，この範囲を超えるものについては不良品といて品質検査時に弾くことになっている．

今，製品の歩留まり率（検品の際に不良品として弾かれ**なかった**製品の割合）の向上を狙って，製造工程を変更を計画している．この工程変更によって，製品の品質のバラツキが抑えられるかどうかを検証するために，変更前の製造された製品と，試験的に導入した新工程での製品をランダムに200個ずつ取り出してきた[データ](./practice/07_work_3.csv)．このデータを用いて，以下のことを行え．

1. このデータの冒頭6行分をhead()を用いて確認し，このデータの形式か確認せよ．
1. 変更前と変更後のそれぞれの平均と標準偏差を算出するとともに，それらを棒グラフで示せ．棒グラフにはエラーバーも付与すること．
1. 変更前と変更後とで品質検査の点数そのものに有意な差があるかどうかを検証せよ．
1. 変更前と変更後とで品質検査の点数のバラツキに有意な差があるかどうかを検証せよ．


```{r include =F}
set.seed(42)

# データの個数
num_samples <- 200
before_change <- round(truncnorm::rtruncnorm(num_samples, a=0, b=100, mean = 70, sd = 0.06),3)
after_change <- round(truncnorm::rtruncnorm(num_samples, a=0, b=100, mean = 70, sd = 0.03),3)

data <- tibble(
  変更前 = before_change,
  変更後 = after_change
)

write.csv(data, "./practice/07_work_3.csv",row.names=FALSE)
```
:::


# 独立性の検定
続いて比率の比較を行う方法を説明する．比率の検定とは，例えば以下の表のような「クロス集計表」が作られている時に，列方向に並べた属性変数Aと行方向に並べた属性変数Bが互いに独立しているのか，何等かの関係性があるのかを検定する方法である．**帰無仮説は「互いに独立している」**であり，それが否定することによって「関係性がある」と結論づける統計方法である．

```{r echo=FALSE}
# クロス集計表の作成
mydata_cross <- matrix(c(10, 20, 20, 40), nrow=2, byrow=TRUE)
colnames(mydata_cross) <- c("Bあり", "Bなし")
rownames(mydata_cross) <- c("Aあり", "Aなし")
mydata_cross <- as.table(mydata_cross)


kable(mydata_cross, format = "html", table.attr = "class='custom-table'")


```


## 「独立」とは？

独立とは，たとえば上記の表の場合，条件Aが「あり」の場合での条件Bの「あり」と「なし」の比率は1:2であるが，条件Aが「なし」の場合での条件Bの「あり」と「なし」の比率も2:1である．すなわち，条件Aが「あり」か「なし」かによって，条件Bの「あり」か「なし」かのなり易さ（生起確率）に違いはない．つまり，条件Bの「あり」「なし」のいずれになるかには条件Aは関わってこない．このような場合には，**条件Aと条件Bが互いに独立している**と呼ぶ．

逆に以下の表のような場合，条件Aが「あり」の場合での条件Bの「あり」と「なし」の比率は1:2であるが，条件Aが「なし」の場合での条件Bの「あり」と「なし」の比率は2:1である．すなわち，条件Aが「あり」か「なし」かによって，条件Bの「あり」か「なし」かの生起確率が異なっている．このような場合には，条件Aと条件Bが互いに独立していないと呼ぶ．

```{r echo=FALSE}
# クロス集計表の作成
mydata_cross <- matrix(c(10, 20, 40, 20), nrow=2, byrow=TRUE)
colnames(mydata_cross) <- c("Bあり", "Bなし")
rownames(mydata_cross) <- c("Aあり", "Aなし")
mydata_cross <- as.table(mydata_cross)

kable(mydata_cross, format = "html", table.attr = "class='custom-table'")


```


上記の1つ目の例では両方とも1:2の比で完全に一致しているが，実際には，誤差が入り込む．では，実際に何らかのクロス集計表がえられたときに，比率にどの程度以上の差があれば「独立していない＝関連性がある」とみなすのか？その検定を行うのが独立性の検定である．

## カイ2乗検定とフィッシャーの正確確率検定

独立性の検定を行う方法として，**カイ2乗検定**と**フィッシャーの正確確率検定**がある．以下，それぞれの方法のRでの行い方を説明する．

### カイ2乗検定の方法
独立性の検定では**カイ2乗($\chi^2$)検定**を用いるのが基本である．．
カイ2乗検定は，Rの`chisq.test()`関数を用いて行う．この関数は，以下の2通りの方法で実行可能である．

1. 第1引数に要因Aについてのベクトルデータ，第2引数に要因Bについてのベクトルデータを与える
1. クロス集計したテーブルデータを引数して与える．

通常，比率の検定を行う際にはその前段でクロス集計を行うのが一般的なので，後者の場合だとその結果をそのまま使うことができる．

クロス集計表の作成は，Rの`table()`関数を用いて行う．この関数の引数は以下の通りである．

- 第1引数: 行方向（左側）に並べるベクトルデータ（要因A）
- 第2引数: 列方向（上側）に並べるベクトルデータ（要因B）

なお，要因A，要因Bにそれぞれ与えるベクトルデータは**要因型**である必要がある．

また，ここで用いられている要因A，要因Bの各ベクトルデータは互いに対応関係があるデータである．すなわち，例えば要因Aのベクトルの1つ目のデータと要因Bの1つ目のデータは同じサンプルが取られたデータである，ということである．このように対応関係がデータの並びによって取られていくので，分析を掛けるにあたっては，各ベクトルのデータの並びがきちんと合っているかを注意しておく必要がある．

:::practice
ある試験を受験した100人の受験者について，性別(男性, 女性）と合否（不合格, 合格）のデータ（[リンク](./practice/example_chisq.csv)）がある．このデータから，クロス集計表を作成するとともに，性別と合否の間に関連性があるのかどうかを検証せよ．
:::

```{r include=FALSE}
#./practice/example_chisq.csvの作成
set.seed(42)
num_samples <- 100
性別 <- rbinom(num_samples, 1, 0.5)
合否 <- rbinom(num_samples, 1, 0.4)
性別 <- recode(性別, `0`="男性", `1`="女性")
合否 <- recode(合否, `0`="不合格", `1`="合格")
data <- tibble(
  性別 = 性別,
  合否 = 合否,
)
write_csv(data, "./practice/example_07_chisq.csv")

```

Rのスクリプトは以下の通りとなる．

```{r}
mydata_chisq <- read.csv(
  "./practice/example_chisq.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

# 要因型に変換
mydata_chisq$合否 <- as.factor(mydata_chisq$合否)
mydata_chisq$性別 <- as.factor(mydata_chisq$性別)

# データの確認
head(mydata_chisq)
summary(mydata_chisq)

#クロス集計表の作成 
# クロス集計表にはtable()関数を用いる.引数には行，列に割り振りたい要因を与える．
# 以下のように引数に名前を与えることもできる．
cross_table <- table("性別"=mydata_chisq$性別, "合否"=mydata_chisq$合否)
cross_table

#カイ二乗検定
## 要因Aと要因Bをそれぞれベクトルデータとして与える方法
chisq.test(mydata_chisq$性別, mydata_chisq$合否)
## クロス集計表の結果を与える方法
chisq.test(cross_table)
```
この結果から，P値が0.6284となっており，5%の有意水準を下回っていないため，性別と合否の間に有意な関連性があるとは言えない．すなわち，性別は入試の合否に対して「独立である」（影響を与えていない）という可能性が否定出来ないという結果となった．


### Fisherの正確確率検定の方法

カイ2乗検定はクロス集計した際の**いずれかのセルが5以下の値の場合には正確な値は返してこない場合がある**．そこでそうしたケースでも対応できるような方法としてFisherの正確確率検定というものがある．

Fisherの正確確率検定は，Rの`Fisher.test()`関数を用いて行う．引数の与え方は`chisq.test`と同様に2通りの方法が可能である．

:::practice
ある喫茶店でコーヒーを注文したかどうか（しなかった，した）と，スイーツを注文したかどうか（しなかった，した）のデータ（[リンク](./practice/example_fisher.csv)）がある．このデータから，クロス集計表を作成するとともに，コーヒーを注文するかどうかとスイーツを注文するかどうかの間に関連性があるのかどうかを検証せよ．
:::

```{r include=FALSE}
#./practice/example_fisher.csv
set.seed(2)
num_samples <- 50
珈琲 <- c(rep(1,35),rep(0,15))
甘味 <- c(rbinom(35, 1, 0.6),rbinom(15, 1, 0.1))
珈琲 <- recode(珈琲, `0`="しなかった", `1`="した")
甘味 <- recode(甘味, `0`="しなかった", `1`="した")
data <- tibble(
  珈琲 = 珈琲,
  甘味 = 甘味,
)
write_csv(data, "./practice/example_07_fisher.csv")

```

Rのスクリプトは以下の通りとなる．

```{r}
mydata_fisher <- read.csv(
  "./practice/example_fisher.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

mydata_fisher$珈琲 <- as.factor(mydata_fisher$珈琲)
mydata_fisher$甘味 <- as.factor(mydata_fisher$甘味)
summary(mydata_fisher)

#クロス集計表の作成
cross_table <- table("珈琲"=mydata_fisher$珈琲, "甘味"=mydata_fisher$甘味)
cross_table

```
この結果から，スイーツもコーヒーも注文していない人が3人しかいないためカイ2乗検定では対応できないデータとなっている．
このため，フィッシャーの正確確率検定を行う．

```{r}
#Fisherの正確確率検定
## 要因Aと要因Bをそれぞれベクトルデータとして与える方法
fisher.test(mydata_fisher$珈琲, mydata_fisher$甘味)
## クロス集計表の結果を与える方法
fisher.test(cross_table)
```


P値が0.0049となっており，1%の有意水準を下回っているため，コーヒーを注文するかしないかとスイーツを注文するかしないかの間に有意な関連性があると結論づけることができる．

## カイ2乗検定とFisherの正確確率検定の使い分け
上記の通り，一般にいずれかのセルが5以下の小さな値になっている場合には，カイ2乗検定では正しい結果が導けなくなるので，Fisherの正確確率検定が良い，と述べた．であるならば，どのような場合でもFisherの正確確率検定を用いればよいではないか，という意見が出てくるだろう．

確かにFisherの正確確率検定を常に用いれば，カイ2乗検定の問題を回避できる．しかし，Fisherの正確確率検定は，カイ2乗検定に比べて計算量が多くなるというデメリットがある．この量はデータのサンプル数に依存しており，サンプル数が大きい場合には計算規模が大きくなりすぎてアプリケーションがフリーズしたり，あるいはRの側でエラーを返してくることもある．そのため，データの規模が大きい場合には，カイ2乗検定を用いることが一般的である．

実際にどれくらいのサンプル数であればカイ2乗検定の方が良いかの目安というものは特には存在しないので，サンプル数が5以上なのであれば，一旦はFisherの正確確率検定を実施してみて，もし何らかの問題が発生すればカイ2乗検定に切り替える，という方針が良いだろう．


## 結果の報告方法
クロス集計表の結果を報告する際には，まずはクロス集計表をしめす．その上で，カイ2乗検定を使った場合，その結果に表記されている値を引用しながら，「カイ2乗検定の結果2つの群の間に有意な関連性があることが確認された（$\chi^2$(`df`)=`X-squared`, P=`p-value`）」と文章の中で記載する．`df`は自由度を示し，`X-squared`はカイ2乗値を，`p-value`はP値を示す．一方，フィッシャーの正確確率検定の場合には，「フィッシャーの正確確率検定の結果2つの群の間に有意な関連性があることが確認された（P=`p-value`）」と記載する．

## 3つ以上の水準を持つ要因での独立性の検定
上記の例では，2つの水準を持つ要因同士（つまりクロス集計表が$2 \times 2$となる）での独立性の検定を行ったが，3つ以上の水準を持つ要因での独立性の検定も同様に行うことができる．その場合には，クロス集計表を作成する際には，`table()`関数によって作成したクロス集計表をそのまま`chisq.test()`関数や`fisher.test()`関数に与えることで検定を行うことができる．

:::practice
ある大学の食堂の利用頻度が学部によって異なるのではないかという疑問が生じた．そこで，ある大学の学生に対して，学部（文学部，理学部，工学部）と食堂の利用頻度（毎日，週に3回以上，週に1回以上，月に1回以上，年に1回以上，利用しない）について尋ねるアンケートを行った．その結果，次のようなデータ（[リンク](./practice/example_Restaurant.csv)）が得られた．このデータから，学部と食堂の利用頻度の間に関連性があるのかを検証せよ．
:::

```{r include=FALSE}
#./practice/example_Restaurant.csvの作成
set.seed(42)

文学部 <- sample(c("毎日", "週に3回以上", "週に1回以上", "月に1回以上", "年に1回以上", "利用しない"), 200, replace = TRUE, prob=c(0.1, 0.1, 0.2, 0.3, 0.2, 0.1))

理学部 <- sample(c("毎日", "週に3回以上", "週に1回以上", "月に1回以上", "年に1回以上", "利用しない"), 400, replace = TRUE, prob=c(0.4, 0.3, 0.1, 0.1, 0.05, 0.05))

工学部 <- sample(c("毎日", "週に3回以上", "週に1回以上", "月に1回以上", "年に1回以上", "利用しない"), 700, replace = TRUE, prob=c(0.7, 0.2, 0.05, 0.05, 0.025, 0.025))

data <- tibble(
  学部 = c(rep("文学部", 200), rep("理学部", 400), rep("工学部", 700)),
  食堂利用頻度 = c(文学部, 理学部, 工学部)
)

data<- data[sample(nrow(data)),]

write.csv(data, "./practice/example_07_Restaurant.csv",row.names=FALSE)
```

```{r error=T}
mydata_restaurant <- read.csv(
  "./practice/example_Restaurant.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

mydata_restaurant$学部 <- as.factor(mydata_restaurant$学部)
mydata_restaurant$食堂利用頻度 <- as.factor(mydata_restaurant$食堂利用頻度)
summary(mydata_restaurant)

#クロス集計表の作成
cross_table <- table(mydata_restaurant$学部, mydata_restaurant$食堂利用頻度)
cross_table

# カイ2乗検定
chisq.test(cross_table)
```
この結果から，P値が$2.2 \times 10^{-16}$未満という非常に小さな値となっており，有意水準を裕に下回っているため，学部と食堂の利用頻度の間に有意な関連性がある，すなわち，学部によって職宇利用頻度は異なると結論づけることができる．

このように3つ以上の水準を持つ要因での独立性も，chisq.test()で検証することができる．


ちなみ，このデータをfisher.testで行った場合には以下の通りエラーが出力される．

```{r error=T}
fisher.test(cross_table)
```

これは計算量が膨大になり，計算のためのメモリ領域(エラーメッセージのworkplace)が足りないことによって生じたエラーである．メッセージにあるとおり，以下の例の通り，workplaceに大きな数字を設定してやれば（以下の例では2e9=$2\times 10^9$という膨大な大きさのメモリを設定している），計算させることができるがかもしれないが，計算できたとして膨大な計算時間がかかってしまうだろう．

```{r eval=F}
fisher.test(cross_table, workspace=2e9)
```

サンプル数が大きい場合にはカイ2乗検定でも十分に正確な結果が出力されるので，chisq.testで十分である．




:::work
ある大学3年生の学生が，最近後輩たちが使っているメッセンジャーアプリに違いが出てきているように感じている．具体的には，自分達はLINEを主なメッセンジャーツールとして使っているが，最近の後輩はInstagramのDMを主なツールとして使っているようだ．そこで実際に自分達の世代と後輩世代と使っているメッセンジャーアプリに違いがあるのかをゼミ研究として調査をしてみることにした．

調査は，大学1から4年生の学生約2000人に対して，LINEとInstagramのどちらを主なメッセンジャーツールとして使っているかを尋ねるアンケートをメールで送付した．結果，次のようなデータ（[リンク](./practice/07_work_4.csv)）が得られた．このデータから，先輩群(3，4年生）と後輩群(1，2年生）の間で使っているメッセンジャーアプリに違いがあるのかを検証せよ．


```{r include=FALSE}
#./practice/07_work_4.csvの作成
set.seed(42)
num_samples_Elder <- 321
num_samples_Younger <- 535

SNS_Elder <- sample(c("LINE", "Instagram"), num_samples_Elder, replace = TRUE, prob=c(0.7, 0.3))
SNS_Younger <- sample(c("LINE", "Instagram"), num_samples_Younger, replace = TRUE, prob=c(0.4, 0.6))

data <- tibble(
  年代 = c(rep("先輩", num_samples_Elder), rep("後輩", num_samples_Younger)),
  SNS = c(SNS_Elder, SNS_Younger)
)

shuffled_df <- data[sample(nrow(data)), ]

write.csv(shuffled_df, "./practice/07_work_4.csv",row.names=FALSE)
```
:::

:::work
ある大学のあるゼミの学生が，ふと「政治学のゼミにいる学生はそのほかのゼミの学生より．選挙に行く人が多いのだろうか」という疑問を抱いた．これを検証するために，実際に最近あった衆議院選挙に投票に行ったかどうかを尋ねるアンケートを行った．その結果，次のようなデータ（[リンク](./practice/07_work_5.csv)）が得られた．このデータから，政治学ゼミの学生とその他のゼミの学生の間で投票に行く人の割合に違いがあるのかを検証せよ．


```{r include=FALSE}
set.seed(32)
num_samples_Political <- 15
num_samples_Other <- 180

Voting_Political <- sample(c("Yes", "No"), num_samples_Political, replace = TRUE, prob=c(0.75, 0.25))
Voting_Other <- sample(c("Yes", "No"), num_samples_Other, replace = TRUE, prob=c(0.45, 0.55))

data <- tibble(
  ゼミ = c(rep("政治学", num_samples_Political), rep("その他", num_samples_Other)),
  投票 = c(Voting_Political, Voting_Other)
)

#シャッフル
shuffled_df <- data[sample(nrow(data)), ]

write.csv(shuffled_df, "./practice/07_work_5.csv",row.names=FALSE)

```
:::




# 比率の差の検定
独立性の検定と類似したものとして「比率の差の検定」というものもある．独立性の検定が要因Aと要因Bのクロス集計表から，**AとBの間に関連性があるかどうか**を検証するのに対して，比率の差の検定は，要因Aの2つの水準（例えば，男性と女性）の間で，それぞれの中での何らかの属性水準の占める割合（例えば，合格率＝受験者に占める合格者の割合）の差が有意であるかどうかを検証するものである．この場合にはZ検定を用いる．

比率の差の検定における**帰無仮説は「2つの水準間で比率に差がない」**である．

## Z検定の方法

RでZ検定を行う場合には`prop.test()`関数を用いて行う．
この関数は，以下の引数を取る．

- 第1引数: 比較したい2つのグループの成功数（比率を計算するときの分子にくる数）を並べたベクトルデータ．並べ方はc(比較先, 比較元)とする．
- 第2引数: 比較したい2つのグループの試行総数（（比率を計算するときの分母にくる数）を並べたベクトルデータ．並べ方は同上．

先ほどの合否の例で男女での合格率に差があるかを検証してみよう．第1引数には，今回だと男女それぞれの合格者数をベクトルで与え，第2引数には，男女それぞれの受験者数をベクトルで与えることになる．

このためまずは男女別の受験者数と合格者数を求める必要がある．
`filter()`関数と`length()`（ベクトルデータの要素数を返す）や`nrow()`（データフレームの行数＝サンプル数を返す）を用いてデータを抽出することで求めることもできるが，Rには`sum()`関数というものがある．
この関数は元々は与えたベクトルデータの総和を返す関数であるが，以下のように検索条件の式を与えることによって，それにマッチしたデータの数を返してくれる．

:::ref
<details>
<summary>sum関数＋検索条件</summary>
sum関数に検索条件を与えると，そのデータ数が返されると上で述べているが，これは，sum関数にそういう機能のがそ備わっているというわけではない．ここでsum関数が行なっていることはあくまで「和」の算出である．

ポイントは，検索条件の式にある．[ベクトルデータの検索](RText_03_BasicUsage2.html#ベクトルの検索)で解説した通り，ベクトルと値を`==`で結ぶと，ベクトルに含まれる各値が与えた値と一致しているかどうかの照合が行われ，マッチした場合には`TRUE`が，マッチしなかった場合には`FALSE`が入った元のベクトルと同じ長さのベクトルが返される（`==`は単なる等号ではなく，比較演算子と言って，`+`や`-`などと同じように左右のデータに所定の処理を行ない，元のベクトルと同じ長さのベクトルを返す演算子である）．

実際に以下の例ではTestというベクトルと"B"を`==`にかけており，その結果を`Res`に格納した上でPrintさせている．

```{r}
Test <- c("A", "B", "C", "D", "E", "F")
res<-Test == "B"
print(res)
```

結果を見ると，２つ目が`TRUE`，それ以外が`FALSE`となっているベクトルが返されているのがわかる．

この`FALSE`と`TRUE`は論理型と呼ばれるデータ型の値であるが，内部的には`FALSE`=0, `TRUE`=1として処理されている．このため検索条件をsum()に与えることによって，検索条件にマッチしたものの数が数え上げられることになる，というわけである．
</details>
:::


```{r}
mydata_chisq <- read.csv(
  "./practice/example_chisq.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

mydata_chisq$合否 <- as.factor(mydata_chisq$合否)
mydata_chisq$性別 <- as.factor(mydata_chisq$性別)
summary(mydata_chisq)

# クロス集計表の作成
cross_table <- table("性別"=mydata_chisq$性別, "合否"=mydata_chisq$合否)
print(cross_table)
```

この結果から，合格者は女性で27人，男性で19人．受験者数は女性で55人，男性で45人であることがわかる．

男女別の合格者数, 受験者数が求まったので，これらを使ってprop.test()関数を実行する．

```{r}
# それぞれの成功数 (Success) と試行数 (Total) をベクトルにする
success <- c(27, 19) 
total <- c(55, 45)
# 確認のためそれぞれの合格率を算出
print(success/total)

# Z検定
prop.test(success,total)
```

結果として，男性と女性で合格率には有意な差はない，という結果となった．

なお有意確率を見ると，実は先の独立性の検定でのchisq.testの出力結果と同じ値となっている．
これは，特に今回のように$2\times 2$のクロス集計が可能である場合，比率の差に有意な差があるかないかと，要因間の関連性があるかどうかという検定が，数学的には同じであるためである．

一方，3つ以上の水準を持つ要因を分析対象としている場合（すなわち，$3\times 2$以上のクロス集計となる場合）には独立性の検定と比率の差の検定は意味合いも，数学的にも，処理の面でも異なるものとなる．
立性の検定においては，先にも述べた通り，水準すべてを考慮したうえで，全体として独立か，関連性があるのかを検定することになる一方，比率の差の検定の場合は，「差」というものはそもそも**2つのものの間での比較**でなので，3つ以上の水準を含んだ要因を分析対象にしていた場合でも，それらの要因の中のどの水準とどの水準を比べるのか，という話になる．

例えば，ある要因でA, B, Cという群分けをして，合格率を比べる，という場合，全体として群分けと合格率に関係があるか，ということを調べたいのであれば，独立性の検定であり，[こちら](#3つ以上の水準を持つ要因での独立性の検定)で述べた通りにカイ2乗検定を掛ける．一方で，各群の間での合格率の差が有意であるかどうかを調べたい，という場合にはA-B，B-C，C-Aという3つの組み合わせのそれぞれでZ検定を行う，ということになる（なお，この場合，次に述べる「多重性問題」への対応が必要になる）．

:::ref
<details>
<summary>数値をコードで入力する方法</summary>
上記の例のように，直接数値を自分で手入力する方法でも全く問題はないが，手入力の場合，入力時に数値を誤ってしまう可能性がある．そうしたヒューマンエラーを避けるために，以下のようにコードで計算させる方法もある．

```{r}
cross_table<-table(mydata_chisq$性別, mydata_chisq$合否)
print(cross_table)

success <- c(cross_table[1,1], cross_table[2,1]) # [行, 列]で指定する 
total <- c(cross_table[1,1]+cross_table[1,2], cross_table[2,1]+cross_table[2,2])
# 確認のためそれぞれの合格率を算出
print(success/total)

# Z検定
prop.test(success,total)
```
</details>
:::



:::work
ある学部の就職支援担当の教員は，今年度の卒業予定者の9月末時点での内定率が例年より高いように感じた．今年度は卒業予定者153人中，内定を得ている学生は141名である．一方，過去10年間の状況を通算すると同時点に内定を得ていたのはのべ1732名中，1492名であった．単純に比較するならば，今年度は約92%の内定率であるのに対し，過去10年間の平均内定率は約86%である．この内定率の差は有意であるかどうかを検証せよ．（ヒント：この場合はすでに成功数と試行総数が端的に文章に与えられている！）
:::


# 多重比較

例えば以下のようなケースではどのような分析をすればよいだろうか．

:::practice
あるオンライン小売業者が，新しい広告キャンペーンを展開する際，3つの異なる広告バナーを作成した．それぞれの広告バナーには異なるキャッチコピーとデザインが使用されている．マーケティングチームは，どの広告がクリック率（広告が表示された回数に対する広告がクリックされた回数）を最も向上させるのかを調べるため，3つの広告キャンペーンを同時に2か月間実施し，毎日のA，B，Cのそれぞれの広告バナーのクリック率を調べた．その結果，次のようなデータが得られた．このデータをもとに，どの広告バナーが最もクリック率を向上させるのかを検証せよ（[リンク](./practice/example_multcomp.csv)）．

```{r include=FALSE}
#./practice/example_multcomp.csvの作成
set.seed(34)
num_samples <- 62
Date <- seq.Date(from = as.Date("2024-07-01"), by = "day", length.out = num_samples)
A <- round(rnorm(num_samples, mean = 0.08, sd = 0.02),4)
B <- round(rnorm(num_samples, mean = 0.05, sd = 0.003),4)
C <- round(rnorm(num_samples, mean = 0.06, sd = 0.004),4)

data <- tibble(
  Date = Date,
  A = A,
  B = B,
  C = C
)
write_csv(data, "./practice/example_07_multcomp.csv")

```
:::

2つのバナーでの比較だった場合には，単純にt検定を実施すれば良いが，今回の例の場合には3つの比較となっている．このように3つ以上のデータで，各データ間の平均の比較を行うような場合には，どのようにすればよいだろうか？

## 検定の多重性問題

こういうケースでシンプルに浮かぶ方法としては，「AとB」「BとC」「CとA」という形で，1対1の組み合わせを作り，それぞれの組み合わせで平均値の比較を行う（このような比較のことを**一対比較**という）というものである．

例えば，平均値の値としてはA＜B＜Cとなっていたとして，上記の3つの組み合わせで，それぞれで差が有意であるかどうかを一対比較のt検定で調べた結果，「BとCの間には有意差はないが，AとB，CとAの間には有意差がある」という結果となった場合，「BとCの間にはそれほどの差はないが，AはB，Cに比べて広告としては弱い」という結論を出すことができる．

ただ，ここで注意しないといけないのは，***検定の多重性***という問題である

### そもそもP値とは

検定では一般に5%を基準として，P値がこれを下回れば「有意である」と判定し，逆に上回っていた時には「測定時に生じた単なる誤差の可能性を否定できない」と判断する．

このP値の意味や見方は[こちら](#比較の原理)で説明しているが，要するに「帰無仮説が真である確率」のことであり，言い換えれば「有意であるという判定結果が誤っている確率」である．つまり，P値が5％であった場合には，本当は「単なる誤差」であるのに「有意である」と誤って判定する確率が5\%ある，という意味である（このことから「有意水準」という言葉の変わりに「**危険率**」という言葉が用いられることもある）．

このことから，「有意水準を**下回っていれば**有意とする」ということについて，なぜ**「下回っていれば」**なのかは，要するに「誤っている確率が5\%未満であれば，誤る可能性は低いわけだから，結果を信頼してもよいだろう」と判断しているということである．ちなみに，「5\%」を「十分に低い」の基準としているのは特段の理由があってのことではなく，統計学において経験上，設定された基準でしかない．

### 検定を多重化すると誤り率が上る！？
ある事柄Aについて，5\%の有意水準で検定をしたときには，仮に「有意だ」と判定しても，それは5\%の確率で誤っているということである．逆に言えば，95\%の確率で正しいということである．

一方，5\%水準で別の事柄Bを検定して「有意だ」と判定した場合，同じようにその判定結果は95\%の確率で正しい．

では，**「AとBの両方が正しい結果である」**確率はいくらであろうか？

Aが正しい確率：95% (0.95)

Bが正しい確率：95% (0.95)

$\rarrow$ 両方がそろって正しい確率：0.95×0.95＝0.9025 (90.25%) となる．

つまり，AとBがそれぞれ個別には「95%の確率で正しい」となっていたとしても，**AとB両方が同時に正しい結果である確率**は90.25%となり，逆に「AとBのいずれか一方が間違っている」，もしくは「両方間違っている」確率は約10%になるということである．

:::ref
より正確には，以下のような表となる．

|  | Bの判定は正しい | Bの判定は誤り |
|:---|:---|:---|
| **Aの判定は正しい** | 0.95×0.95＝0.9025 | 0.95×0.05＝0.0475 |
| **Aの判定は誤り** | 0.05×0.95＝0.0475 | 0.05×0.05＝0.025 |

この表から，AとBの両方が正しい確率は0.9025となる一方，AとBの少なくともどちらか一方が誤っている確率は0.0475×2＋0.025＝0.0975となる．
:::

当然ながら判定は「両方正しい結果」であってほしい．しかしながら，個別に5%水準で判定をして，それを組み合わせるということをすると，「両方ともに正しい結果である確率」は90%ほどとなってしまう．

これは，さらにCという事柄についての検定を行うとすると，A，B，Cの3つがそろって正しい結果である確率は，

95%×95%×95%＝85.73%

同様に事柄の検定の数を増やすと，

- 4つ：95% × 95% × 95% × 95%＝81.45%
- 5つ：95% × 95% × 95% × 95% × 95%＝77.38%
- 6つ：95% × 95% × 95% × 95% × 95%×95%＝73.51%

となってしまう．

このように，検定を多重に行ってしまうと，個々の検定の結果が正しい確率が95%（誤り率が5%）でも，多重に行った検定が全て正しい確率は95%を下回ってしまう．これが**検定の多重性問題**である．

### 検定の多重性問題の解決方法
「検定の多重性問題を解決する」というのは，つまりは**多重に行った検定の「全てが正しい」となる確率が95%を下回らないようにすること**である．

そのための方法として，もっとも単純で簡単な方法は，個別の検定を行う際の有意水準である「5%」という値を検定を行う回数で割った値を個別の検定の有意水準とすることである．

より具体的には，例えば，

- 2回の検定を行うのであれば，5%÷2＝2.5%を個々の検定の有意水準とする．
- 3回の検定を行うのであれば，5%÷3≒1.67%を個々の検定の有意水準とする．（端数は切り上げ）
- 4回の検定を行うのであれば，5%÷4＝1.25%を個々の検定の有意水準とする．
- 5回の検定を行うのであれば，5%÷5＝1%を個々の検定の有意水準とする．
- 6回の検定を行うのであれば，5%÷6≒0.84%を個々の検定の有意水準とする．（端数は切り上げ）

ということである．

このように補正すると，多重に行った検定が全て正しい確率は以下の通りとなる．

| 検定回数 |全て正しい確率 |
|---|---|
|2回の場合|97.5% × 97.5％＝95.06%|
|3回の場合|98.33% × 98.33% × 98.33%＝95.07%|
|4回の場合|98.75% × 98.75% × 98.75% × 98.75%＝95.09%|
|5回の場合|99% × 99% × 99% × 99% × 99%＝95.10%|
|6回の場合|99.16% × 99.16% × 99.16% × 99.16% × 99.16% × 99.16%＝95.06%|

このように，多重検定を行う際に実際に行う検定の数で有意水準を割った値を個々の有意性評価の基準とする方法を**ボンフェローニ（Bonferroni）補正**と呼ぶ．

実際には有意水準を補正するのではなく，確率であるP値の方を補正し（検定の回数を掛ける），補正された有意確率が5\%を上回るか下回るかで評価することが多い．すなわち，

- 2回の検定であれば，一対比較時のP値を2倍する
- 3回の検定であれば，一対比較時のP値を3倍する
- 4回の検定であれば，一対比較時のP値を4倍する
- 5回の検定であれば，一対比較時のP値を5倍する

・・・

とする．

### 補正の方法
補正方法には他にもいくつかの方法があるが，ボンフェローニ補正は最もシンプルで直感的な方法であるため，手計算を行う際にはよく使われる．

ただ，ボンフェローニ補正は，検定の数が増えるにつれて有意水準が厳しくなるという性質があるため，検定の数が多い場合には，ホルム法やシダック法，ダンスカー法などの補正方法を用いることもある．

以下で紹介するRでの多重比較の補正方法は，ホルム補正がデフォルトとなっている．


## 多重比較時のP値の補正方法

Rでは，`p.adjust()`という関数を用いて，上記のようなP値の補正を行うことができる．引数は以下の通りである．

- 第1引数：多重比較時の個々の一対比較の結果のP値をまとめたものベクトルで与える．
- 第2引数（省略可）：補正方法を指定する．デフォルトではholm補正を行うように設定されており，省略した場合にはholm補正となる．上記のボンフェローニ補正を行う場合には，`method="bonferroni"`と指定する．

出力結果は，補正されたP値を返す．この補正後のP値が5%を下回るかで，その組み合わせが有意であるかどうかを判断する．

### 平均の多重比較

先の例題では以下のようになる．

```{r}
mydata_multcomp <- read.csv(
  "./practice/example_multcomp.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

# データの確認
head(mydata_multcomp)

# AとBの比較
res_A_B<-t.test(mydata_multcomp$A, mydata_multcomp$B)
print(res_A_B)

# BとCの比較
res_B_C<-t.test(mydata_multcomp$B, mydata_multcomp$C)
print(res_B_C)

# CとAの比較
res_C_A<-t.test(mydata_multcomp$C, mydata_multcomp$A)
print(res_C_A)

# 各P値をベクトルにまとめる．
# それぞれのP値は$p.valueで取得できる
# わかりやすさのため，名前付きベクトルにしている．
P_values <- c(
  AとB=res_A_B$p.value, 
  BとC=res_B_C$p.value, 
  CとA=res_C_A$p.value
  )

print(P_values)

# 多重比較のP値　補正方法を指定していないのでホルム補正が用いられる
p.adjust(P_values)

# 多重比較のP値のボンフェローニ補正
p.adjust(P_values, method="bonferroni")


```

これらの出力結果から，今回の場合だと補正後でも，いずれの組み合わせでも有意な差があることが分かった．

このp.adjust()を用いた補正方法は，平均の比較，分散の比較，比率の比較いずれの比較においても用いることができる．

### 分散の多重比較

分散の多重比較の例を示す．

:::practice
ある製造工程において、製品の重量を測定した結果、以下のようなデータが得られた．このデータをもとに、各工程間の重量のばらつきに有意な差があるかどうかを検証せよ（[リンク](./practice/example_multcomp_var.csv)）．
```{r include=FALSE}
#./practice/example_multcomp_var.csvの作成
set.seed(42)
num_samples <- 20
工程A <- rnorm(num_samples, mean = 100, sd = 5)
工程B <- rnorm(num_samples, mean = 110, sd = 5)
工程C <- rnorm(num_samples, mean = 105, sd = 5)

data <- tibble(
  工程A = 工程A,
  工程B = 工程B,
  工程C = 工程C
)
write_csv(data, "./practice/example_07_multcomp_var.csv")
```
:::

この場合，A-B，B-C，C-Aでそれぞれ分散の一対比較を行った後，そのP値を補正することになる．


```{r}
mydata_multcomp_var <- read.csv(
  "./practice/example_multcomp_var.csv",
  header=T,
  fileEncoding="UTF8"
) # データ読み込み

# データの確認
head(mydata_multcomp_var)

#分散の一対比較
res_AB <- var.test(mydata_multcomp_var$工程A, mydata_multcomp_var$工程B)
res_BC <- var.test(mydata_multcomp_var$工程B, mydata_multcomp_var$工程C)
res_CA <- var.test(mydata_multcomp_var$工程C, mydata_multcomp_var$工程A)

#P値をベクトルにまとめる
P_values_var <- c(
  AとB=res_AB$p.value, 
  BとC=res_BC$p.value, 
  CとA=res_CA$p.value
)
print(P_values_var) #P値の確認

#P値の補正　補正方法は指定していないのでホルム補正が用いられる
p.adjust(P_values_var)

#P値の補正　補正方法はボンフェローニ補正
p.adjust(P_values_var, method = "bonferroni")

# 参考：補正前のP値
p.adjust(P_values_var, method = "none")
```

この結果から、補正を行った結果、全ての組み合わせでP値が0.05を上回っていることが分かる．


### 比率の多重比較

比率の多重比較の例を示す．

:::practice
ある製造工程A，B, Cにおいて、製品の不良品率を測定したするためにランダムに1000個のサンプルを取り出し、不良品かどうかを調べた（良・不良）．その結果、以下のようなデータが得られた．このデータをもとに、各工程間の不良品率に有意な差があるかどうかを検証せよ（[リンク](./practice/example_multcomp_prop.csv)）．
```{r include=FALSE}
#./practice/example_multcomp_prop.csvの作成
set.seed(42)
num_samples <- 1000
工程A <- rbinom(num_samples, 1, 0.05)
工程B <- rbinom(num_samples, 1, 0.1)
工程C <- rbinom(num_samples, 1, 0.12)

工程A <- recode(工程A, `0`="良", `1`="不良")
工程B <- recode(工程B, `0`="良", `1`="不良")
工程C <- recode(工程C, `0`="良", `1`="不良")

data <- tibble(
  工程A = 工程A,
  工程B = 工程B,
  工程C = 工程C
)

write_csv(data, "./practice/example_07_multcomp_prop.csv")
```
:::

この場合もこれまでの多重比較と同様に，A-B，B-C，C-Aでそれぞれ比率の検定を一対比較で行った後，そのP値を補正することになる．

実際に行ってみよう．まずは各工程の不良の数を取得する必要がある．
```{r}
mydata_multcomp_prop <- read.csv(
  "./practice/example_multcomp_prop.csv",
  header=T,
  fileEncoding="UTF8"
) # データ読み込み

# データの確認
mydata_multcomp_prop$工程A <- as.factor(mydata_multcomp_prop$工程A)
mydata_multcomp_prop$工程B <- as.factor(mydata_multcomp_prop$工程B)
mydata_multcomp_prop$工程C <- as.factor(mydata_multcomp_prop$工程C)
head(mydata_multcomp_prop)
summary(mydata_multcomp_prop)
```

summaryの結果から，各工程の不良数は，Aが43，Bが104, Cが121であることがわかった．
総数は課題の設定から1000であることがわかっているので，これらを用いて，まずは一対比較での比率の検定を行う．
後でprop.testの出力結果からp値を取り出したいので，結果はオブジェクトに保存しておく．

```{R}
#比率の検定
res_AB <- prop.test(c(43, 104), c(1000, 1000))
res_BC <- prop.test(c(104, 121), c(1000, 1000))
res_CA <- prop.test(c(121, 43), c(1000, 1000))
```

これらの結果からp値を取り出して，p.adjust()関数を用いて補正を行う．

```{r}
#P値をベクトルにまとめる
P_values_prop <- c(
  AとB=res_AB$p.value, 
  BとC=res_BC$p.value, 
  CとA=res_CA$p.value
)
print(P_values_prop) #P値の確認

#P値の多重比較のための補正　補正方法：ホルム補正（デフォルト値）
p.adjust(P_values_prop)
```

結果として，BとCの間には有意な差はないが，AとB，CとAの間には不良品率に有意な差がある，という結果となった．

なお，今回は工程A, B, Cはワイド形式のデータとして与えられたので，summary()関数で各工程の不良数を取得することができたが，ロング形式でデータが与えられている場合には，table()関数を用いてクロス集計表の作成することによって各工程の不良数を取得することができる．以下では，ロング形式に変換したうえで，table()関数を用いてクロス集計表を作成する例を示す．
```{r}
## ロング形式に変換
library(tidyverse)
mydata_multcomp_prop_long <- pivot_longer(
  mydata_multcomp_prop,
  cols=colnames(mydata_multcomp_prop),
  names_to = "工程",
  values_to= "品質" #測定変数に与える列名
)
mydata_multcomp_prop_long$工程 <- as.factor(mydata_multcomp_prop_long$工程)
mydata_multcomp_prop_long$品質 <- as.factor(mydata_multcomp_prop_long$品質)

# クロス集計表の作成
cross_table <- table(mydata_multcomp_prop_long$工程, mydata_multcomp_prop_long$品質)
print(cross_table)
```





## 平均の多重比較を行う別の方法
さて、[先ほどの例](#平均の多重比較)では、A-B、B-C、C-Aの3つの組み合わせでそれぞれの平均値の差を検定を行った後、p.adjust()関数を用いてそのP値を補正する、という方法をとったが，Rでは平均の多重比較に関しては`pairwise.t.test()`関数を用いることで、個別の検定を行うことなしに多重比較を行うことができる．

pairwise.t.test()関数の引数は以下の通りである．

- 第1引数 : 比較をしたい変数
- 第2引数 : グループ分けに用いる属性変数
- 第3引数pool.sd : FALSEを与える．デフォルトではTRUEとなっており，比較する各データの等分散性が仮定されているが，[こちらで述べている通り](#t検定の種類)，最近では等分散を仮定しないのが一般的となっているためFALSEにする．
- 第4引数p.adjust.method (省略可) : 補正方法を指定する．省略した場合，デフォルトとして設定されているholm補正が用いられる．


ただし，注意しなければならない点として、pairwise.t.test()で多重比較を行う場合には**データはロング形式でなければならない**．今回の例題のデータはワイド形式になっているので，以下の例ではまずはロング形式に変換している．


```{r}
mydata_multcomp <- read.csv(
  "./practice/example_multcomp.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

#ワイド形式からロング形式に変換
mydata_multcomp_long <- pivot_longer(
  mydata_multcomp,
  cols=colnames(mydata_multcomp)[2:4],
  names_to = "広告",
  values_to= "クリック率" #測定変数に与える列名
)

#平均と標準偏差の確認
aggregate(クリック率~広告, data=mydata_multcomp_long, FUN=mean)
aggregate(クリック率~広告, data=mydata_multcomp_long, FUN=sd)

#多重比較の実施　デフォルトではホルム補正
pairwise.t.test(mydata_multcomp_long$クリック率, mydata_multcomp_long$広告, pool.sd = FALSE)

#多重比較の実施　ボンフェローニ補正
pairwise.t.test(mydata_multcomp_long$クリック率, mydata_multcomp_long$広告, pool.sd = FALSE, p.adjust.method="bonferroni")
```
結果の見方として，A-Bの比較のP値（補正済み）が`< 2e-16`となっている．これは，「$2.0 \times 10^{-16}$よりもさらに小さい」を意味しており，ほぼ0と見なせる値である．この結果から，AとBの間には有意な差があると結論づけることができる．
同様に，A-Cの比較のP値（補正済み）は$1.1\times 10^{-15}$であり，有意な差であるといえる．さらに，B-Cについても$4.6\times10^{-6}$であり ，有意な差があるといえる．

これら結果から，広告バナーはAが最もクリック率を向上させる効果があり，次いでCとなり，Bがもっとも効果が低いと結論づけることができる．

なお，pairwise.t.test()関数はデフォルトではホルム補正を行う．ボンフェローニ補正を行いたい場合には，p.adjust.method引数に`"bonferroni"`を指定することで行うことができる．また補正前の値を確認したければ`"none"`を指定するとよい．

なお，補正の結果，P値が1を超えてしまうケースが出てくるが，その場合には「1」と表記される．

### 対応ありデータでの多重比較
対応ありデータでの多重比較を行う場合には，`pairwise.t.test()`関数の引数に`paired=TRUE`のオプションを追加することで行うことができる．

:::practice
あるパンメーカでは新しい食パンの開発に取り組んでおり，小麦粉の種類や使うバターの量などを変えた4種類のパンが市販化の最終候補として残った．そこで，この4つのパンのいずれが消費者に好まれるのかを調査するため，20人の消費者にモニターとして集まってもらい，それぞれのパンを試食してもらい，風味，食感，味わい，色味の4つの項目にそれぞれ5段階評価で得点をつけてもらった（[データ](./practice/example_multcomp_paired.csv)）．その合計点から，いずれの食パンが最も好まれるのかを検証せよ．


```{r include=FALSE}
#./practice/example_multcomp_paired.csvの作成
library(truncnorm)
set.seed(42)
num_samples <- 20
パンA.風味 <- round(rtruncnorm(num_samples, mean = 3.5, sd = 0.5), 0)
パンA.味わい <- round(rtruncnorm(num_samples, mean = 3.5, sd = 0.5), 0)
パンA.食感 <- round(rtruncnorm(num_samples, mean = 3.5, sd = 0.5), 0)
パンA.色味 <- round(rtruncnorm(num_samples, mean = 3.5, sd = 0.5), 0)
パンA <- パンA.風味 + パンA.味わい + パンA.食感 + パンA.色味

パンB.風味 <- round(rtruncnorm(num_samples, mean = 3.3, sd = 0.5), 0)
パンB.味わい <- round(rtruncnorm(num_samples, mean = 3.6, sd = 0.5), 0)
パンB.食感 <- round(rtruncnorm(num_samples, mean = 3.6, sd = 0.5), 0)
パンB.色味 <- round(rtruncnorm(num_samples, mean = 3.1, sd = 0.5), 0)
パンB <- パンB.風味 + パンB.味わい + パンB.食感 + パンB.色味

パンC.風味 <- round(rtruncnorm(num_samples, mean = 4.0, sd = 0.5), 0)
パンC.味わい <- round(rtruncnorm(num_samples, mean = 3.7, sd = 0.5), 0)
パンC.食感 <- round(rtruncnorm(num_samples, mean = 3.8, sd = 0.5), 0)
パンC.色味 <- round(rtruncnorm(num_samples, mean = 3.9, sd = 0.5), 0)
パンC <- パンC.風味 + パンC.味わい + パンC.食感 + パンC.色味

パンD.風味 <- round(rtruncnorm(num_samples, mean = 2.9, sd = 0.5), 0)
パンD.味わい <- round(rtruncnorm(num_samples, mean = 3.1, sd = 0.5), 0)
パンD.食感 <- round(rtruncnorm(num_samples, mean = 3.5, sd = 0.5), 0)
パンD.色味 <- round(rtruncnorm(num_samples, mean = 3.2, sd = 0.5), 0)
パンD <- パンD.風味 + パンD.味わい + パンD.食感 + パンD.色味

data <- tibble(
  協力者No. = rep(1:num_samples, 4),
  パン = rep(c("パンA", "パンB", "パンC", "パンD"), each=num_samples),
  風味 = c(パンA.風味, パンB.風味, パンC.風味, パンD.風味),
  味わい = c(パンA.味わい, パンB.味わい, パンC.味わい, パンD.味わい),
  食感 = c(パンA.食感, パンB.食感, パンC.食感, パンD.食感),
  色味 = c(パンA.色味, パンB.色味, パンC.色味, パンD.色味)
)

data<- data[order(data$協力者No.),] # ソート

write.csv(data, "./practice/example_07_multcomp_paired.csv",row.names=FALSE)
```
:::

この例題の場合，各モニターがA～Dの全てのパンに対して評価を行っており，対応関係のあるデータとなる．そのため，多重比較を行う際には`paired=TRUE`を指定する必要がある．

```{r}
mydata_multcomp_paired <- read.csv(
  "./practice/example_multcomp_paired.csv",
  header=T,
  fileEncoding="UTF8"
) # データ読み込み

# データの確認
head(mydata_multcomp_paired)

# 総合評価の算出
mydata_multcomp_paired$総合評価 <- mydata_multcomp_paired$風味 + 
  mydata_multcomp_paired$味わい + 
  mydata_multcomp_paired$食感 + 
  mydata_multcomp_paired$色味

# 平均と標準偏差の確認
aggregate(総合評価~パン, mydata_multcomp_paired, mean)
aggregate(総合評価~パン, mydata_multcomp_paired, sd)



#多重比較の実施 (ホルム補正)
pairwise.t.test( mydata_multcomp_paired$総合評価,mydata_multcomp_paired$パン, pool.sd=FALSE, paired=TRUE)


```

多重比較の結果を報告するときには，各組み合わせの補正済みのP値を示すことが一般的である．たとえば，上記の例の場合，「パンCはパンA，パンB，パンDのいずれとも有意な差がある（それぞれ有意確率は順に0.034, 0.002, 7.4$\times 10^{-6}$．いずれもholm補正済みの値）」と記述する．

また，平均の比較なのでグラフもあわせて示すことが多い．以下は上記の結果をグラフ表記したものである．

```{R}
# 棒グラフをつくるために平均と標準偏差を収めたデータフレームを作成
平均=aggregate(総合評価~パン, mydata_multcomp_paired, mean)
標準偏差=aggregate(総合評価~パン, mydata_multcomp_paired, sd)

df <- data.frame(
  パン=平均$パン,
  平均=平均$総合評価, 
  標準偏差=標準偏差$総合評価)

# 内容確認
print(df)

# グラフ表示
g <- ggplot(df, aes(x=パン, y=平均, fill=パン)) +
  geom_bar(stat="identity") +
  geom_errorbar(aes(ymin=平均-標準偏差, ymax=平均+標準偏差), width=.1) +
  coord_cartesian(ylim = c(0, 22)) +
  labs(title="各パンの総合評価", x="パン", y="総合評価") +
  # A-Cの結果
  annotate("segment", x = 1, xend = 1, y = 17, yend = 20) +
  annotate("segment", x = 1, xend = 3, y = 20, yend = 20) +
  annotate("segment", x = 3, xend = 3, y = 20, yend = 17) +
  annotate("text", x = 2, y = 21, label = "p=0.0342, *") +
  # B-Cの結果
  annotate("segment", x = 2, xend = 2, y = 17, yend = 19.5) +
  annotate("segment", x = 2, xend = 2.9, y = 19.5, yend = 19.5) +
  annotate("segment", x = 2.9, xend = 2.9, y = 19.5, yend = 17) +
  annotate("text", x = 2.5, y = 18.5, label = "p=0.0023, **") +
  # C-Dの結果
  annotate("segment", x = 4, xend = 4, y = 17, yend = 20) +
  annotate("segment", x = 4, xend = 3.1, y = 20, yend = 20) +
  annotate("segment", x = 3.1, xend = 3.1, y = 20, yend = 17) +
  annotate("text", x = 3.5, y = 21, label = "p=7.4e-06, ***") 


print(g)

```

:::ref
<details>
<summary>行ごとの和や平均の算出</summary>
データフレームに含まれている複数の変数について，サンプルごとの合計や平均を算出する場合には，もっとも簡単なのはそれぞれの変数を`$`で指定して計算させる方法である（上記のその通りに行っている）．
ただ，この方法だと変数が多い場合には書く手間もかかるし，コードも長くなってしまって見づらくなる．

そこで，より短いコードで簡潔に書けるコードとして以下のような書き方がある．

1. `rowSums`, `rowMeans`関数を用いる方法
1. `apply`関数を用いる方法
1. `dplyr`パッケージ（`tidyverse`にふくまれている）の`mutate()`関数を用いる方法．


それぞれ以下で例を示すが，結論としては`mutate`関数を用いる方法が最も簡潔でわかりやすいのでおすすめである．

<p>**`rowSums`, `rowMeans`関数を用いる方法**</p>
計算させたい列を指定する際には，`c(3:6)`のように列番号を指定するか，`c("風味","味わい","食感","色味")`のように列名を指定する．

```{r}
mydata_multcomp_paired$総合評価_和 <- rowSums(mydata_multcomp_paired[c(3:6)]) # 合計
head(mydata_multcomp_paired)

mydata_multcomp_paired$総合評価_平均 <- rowSums(mydata_multcomp_paired[c("風味","味わい","食感","色味")]) # 合計
head(mydata_multcomp_paired)

mydata_multcomp_paired$総合評価_和 <- rowMeans(mydata_multcomp_paired[c(3:6)]) # 平均
head(mydata_multcomp_paired)

mydata_multcomp_paired$総合評価_平均 <- rowMeans(mydata_multcomp_paired[c("風味","味わい","食感","色味")]) # 平均
head(mydata_multcomp_paired)
```

<p>**`apply`関数を用いる方法**</p>
`apply`関数は，行列やデータフレームの各行や各列に対して指定した関数を適用するための関数である．引数は以下の通り3つある．

- 第1引数：処理対象の行列やデータフレーム
- 第2引数：処理を行う方向（1:行方向，2:列方向）
- 第3引数：適用する関数．例えば平均であればmean, 合計であればsum，標準偏差であればsdなど．

今回は行ごとに算出させたいので，第2引数は1となる．第1引数に与えるデータは`rowMeans`や`rowSums`と同様に，列番号を指定するか，列名を指定するかで指定する．

```{r}
mydata_multcomp_paired$総合評価_和 <- apply(mydata_multcomp_paired[c("風味","味わい","食感","色味")], 1, sum) # 合計
head(mydata_multcomp_paired)

mydata_multcomp_paired$総合評価_平均 <- apply(mydata_multcomp_paired[c("風味","味わい","食感","色味")], 1, mean) # 平均
head(mydata_multcomp_paired)
```



<p>**`dplyr`パッケージの`mutate()`関数を用いる方法**</p>
`mutate()`関数は，データフレームに含まれている変数を使って，新しい列を元のデータフレームに追加する関数である．引数は以下の通り．

- 第1引数：データフレーム
- 第2引数以降：新しく追加する列名と，その値をデータフレームに含まれる変数を使って算出する式．複数の列を一度に追加することも可能であり，その場合，同じ要領で順に第3引数，第4引数，第5引数...というように追加していく．

返り値は，元のデータフレームに新しい列が追加されたデータフレームである．したがって，その返り値を受けるオブジェクトは，`rowMeans`や`rowSums`，`apply`のように`$`を用いて特定の列を指定するのではなく，あくまでデータフレームでなければならない

以下の例では，`総合評価_和`と`総合評価_平均`という2つの列を一度に追加している．


なお，`dplyr`パッケージは`tidyverse`にふくまれているので`tidyverse`を読み込んでいるならば，改めてインストールしたり読み込んだりする必要はない．


```{r}
library(tidyverse)
mydata_multcomp_paired <- mutate(mydata_multcomp_paired, 
                                 総合評価_和 = 風味 + 味わい + 食感 + 色味,
                                 総合評価_平均= (風味 + 味わい + 食感 + 色味)/4
                                 )
head(mydata_multcomp_paired)
```

`rowSums`や`rowMeans`はその名の通り，行毎に和や平均を算出する関数であり，最もシンプルである．ただ，あくまで和と平均しか算出できない．

`apply`関数の場合，所定の組み込み関数（`mean`や`sum`，`sd`など）だけでなく，自分で定義した関数を適用することも可能であるため，汎用性という点では`apply`関数が最も優れているだろう．ただ，もともと`apply`関数は行方向にも列方向にも適用できる関数であり，いずれの方向の計算をさせるかを第2引数で指定する（行方向:1，列方向:2）必要があるため，使い方が少し複雑である．また，自分で関数を定義するのは単純に統計分析に用いるよりも1段上のプログラミングの知識が必要になる．

`mutate()`関数は，applyに比べて直感的でわかりやすく，かつ複数の変数を一度に作ることもできるため，使いやすさの面で`apply`よりも優れているので，データフレームの操作においては`mutate()`関数を使うことが多い．

</details>
:::


:::work
全国チェーンのあるスーパーが，割引クーポン、ポイント還元、限定セールのいずれが売り上げ向上に効果的かを検証するための社会実験を行いました．市場規模や顧客特性がほぼ同程度の3つの地域（A，B，C）の店舗を対象に，3日間限定で，A地域では割引クーポン、B地域ではポイント還元、C地域では限定セールを行った．それぞれの割引・還元率は同じとなってる．この3日間の各地域の各店舗の[売上データ](./practice/07_work_6.csv)（各地域の店舗別の売り上げデータ）を用いて，以下の課題を実行せよ．

1. head()とsummary()を用いて与データがどういうデータかの確認を行え．
1. それぞれの地域ごとの売上の平均値と標準偏差を算出せよ．
1. A-B，B-C，C-Aの3つの組み合わせの**それぞれについて**，一対比較の結果を示せ．
1. 一対比較の結果を用いて，p.adjust()関数を用いて補正を行い，各組み合わせのP値を示せ（補正方法はholm補正でよい）．
1. pairwise.t.test()を用いた多重比較を行い，上の課題の結果と一致することを確認せよ（補正方法はholm補正でよい）．
1. この調査結果から導かれる結論を述べよ．

```{r include=FALSE}
library(truncnorm)
set.seed(81)

# 売上データの作成
A <- round(rtruncnorm(12, a=100, mean = 1350000*3, sd = 100000), 0)
B <- round(rtruncnorm(15, a=100, mean = 1320000*3, sd = 100000), 0)
C <- round(rtruncnorm(16, a=100, mean = 1360000*3, sd = 100000), 0)

df_A <- data.frame(
  地域="A",
  店舗=1:12,
  売上=A
)

df_B <- data.frame(
  地域="B",
  店舗=1:15,
  売上=B
)

df_C <- data.frame(
  地域="C",
  店舗=1:16,
  売上=C
)

data <- rbind(df_A, df_B, df_C)

pairwise.t.test(data$売上, data$地域, p.adjust.method="bonf")

write.csv(data, "./practice/07_work_6.csv", row.names=FALSE)
```
:::

:::work
ある学生が卒業研究で，オンライン講義動画を視聴するときの視聴速度と内容の定着率に有意な差があるのかを調べたいと考えた．このことを検証するために，実験協力者36名に対して，1倍速， 1.5倍速, 2倍速の3つの速度で講義を視聴してもらい，それぞれ講義の内容に関するクイズに回答してもらってその成績で比較をする方法を取った．この実験の結果を示すデータが[こちら](./practice/07_work_7.csv)である．このデータを用いて，以下の課題を実行せよ．

1. head()とsummary()を用いて与データがどういうデータかの確認を行え．
1. 1倍速，1.5倍速，2倍速のそれぞれの視聴速度でのクイズの成績の平均値と標準偏差を算出せよ．
1. A-B，B-C，C-Aの3つの組み合わせの**それぞれについて**，一対比較の結果を示せ．
1. 一対比較の結果を用いて，p.adjust()関数を用いて補正を行い，各組み合わせのP値を示せ（補正方法はbonferroni補正を用いること）．
1. pairwise.t.test()を用いた多重比較を行い，上の課題の結果と一致することを確認せよ（補正方法は補正方法はbonferroni補正を用いること）．
1. この実験結果から導かれる結論を述べよ．

```{r include=FALSE}
library(truncnorm)
set.seed(81)

# 成績データ
倍速1.0 <- round(rtruncnorm(36, a=0, b=10, mean = 7.2, sd = 3), 0) 
倍速1.5 <- round(rtruncnorm(36, a=0, b=10, mean = 6.9, sd = 5), 0)
倍速2.0 <- round(rtruncnorm(36, a=0, b=10, mean = 5.1, sd = 4.7), 0)

df_1.0 <- data.frame(
  被験者No.=1:36,
  速度="1倍",
  視聴順序=rep(c("1回目", "2回目", "3回目"), each=12),
  視聴動画=rep(c("A","A", "B", "B", "C", "C"), 3),
  成績=倍速1.0
)

df_1.5 <- data.frame(
  被験者No.=1:36,
  視聴順序=rep(c("2回目", "3回目", "1回目"), each=12),
  視聴動画=rep(c("B","C", "A", "C", "A", "B"), 3),
  速度="1.5倍",
  成績=倍速1.5
)

df_2.0 <- data.frame(
  被験者No.=1:36,
  視聴順序=rep(c("3回目", "1回目", "2回目"), each=12),
  視聴動画=rep(c("C","B", "C", "A", "B", "A"), 3),
  速度="2倍",
  成績=倍速2.0
)

data <- rbind(df_1.0, df_1.5, df_2.0)

data$視聴動画 <- as.factor(data$視聴動画)
data$視聴順序 <- as.factor(data$視聴順序)
data$速度 <- as.factor(data$速度)

table(data$視聴動画,data$視聴順序)
table(data$視聴動画,data$速度)

t.test(df_1.0$成績, df_1.5$成績, paired = T)
t.test(df_2.0$成績, df_1.5$成績, paired = T)
t.test(df_2.0$成績, df_1.0$成績, paired = T)

pairwise.t.test(data$成績, data$速度, paired = T, p.adjust.method="bonf")
write.csv(data, "./practice/07_work_7.csv", row.names=FALSE)
```

:::ref
課題遂行には関係しないが，実際に上記のような実験を行う際に考慮しなければならない点について説明しているので，興味ああれば見てみてほしい．
<details>
<summary>参考　実験条件の組み合せ</summary>
このような実験を行う際には順序効果など，実験結果にバイアスを与える要因を相殺できるように実験を組み必要がある．

今回の例題の場合には，実験を行うにあたって，用いるオンライン講義が同じだと，視聴する毎に成績が良くなると考えられるので，用いるオンライン講義動画は内容の全く異なる3つ（A, B, Cとする）を用意する必要があるだろう．

ただそうすると，A，B, Cをどの順序でどの速度で視聴するのかも結果に影響を与えてしまう．この影響を相殺するためには，考えられるすべての組み合わせで実験を行うことである．

今回の例だと，1つ目に1倍速，2つ目に1.5倍速，3つ目に2倍速の動画を割り当てるケースを考えると，1つ目，2つ目，3つ目にA, B, Cどの動画を割り当てるかの割り当て方は6通りある．それがさらに，1つ目に1倍速，2つ目に2倍速，3つ目に1.5倍速の動画を割り当てるケースや，1つ目に1.5倍速，2つ目に1倍速，3つ目に2倍速の動画を割り当てるケースなど，倍速の割り当て方も6通りになる．各倍速の割り当て方に対して各動画の割り当て方が6通りあるので，全体で6x6=36通りの実験設計が必要となる．

具体的には以下の表のような組み合わせになる，ということである．

|被験者|1つ目に視聴する動画|2つ目に視聴する動画|3つ目に視聴する動画|
|---|---|---|---|
|1|A・1倍速|B・1.5倍速|C・2倍速|
|2|A・1倍速|C・1.5倍速|B・2倍速|
|3|B・1倍速|A・1.5倍速|C・2倍速|
|4|B・1倍速|C・1.5倍速|A・2倍速|
|5|C・1倍速|A・1.5倍速|B・2倍速|
|6|C・1倍速|B・1.5倍速|A・2倍速|
|7|A・1倍速|B・2倍速|C・1.5倍速|
|8|A・1倍速|C・2倍速|B・1.5倍速|
|9|B・1倍速|A・2倍速|C・1.5倍速|
|10|B・1倍速|C・2倍速|A・1.5倍速|
|11|C・1倍速|A・2倍速|B・1.5倍速|
|12|C・1倍速|B・2倍速|A・1.5倍速|
|13|A・1.5倍速|B・1倍速|C・2倍速|
|14|A・1.5倍速|C・1倍速|B・2倍速|
|15|B・1.5倍速|A・1倍速|C・2倍速|
|16|B・1.5倍速|C・1倍速|A・2倍速|
|17|C・1.5倍速|A・1倍速|B・2倍速|
|18|C・1.5倍速|B・1倍速|A・2倍速|
|19|A・1.5倍速|B・2倍速|C・1倍速|
|20|A・1.5倍速|C・2倍速|B・1倍速|
|21|B・1.5倍速|A・2倍速|C・1倍速|
|22|B・1.5倍速|C・2倍速|A・1倍速|
|23|C・1.5倍速|A・2倍速|B・1倍速|
|24|C・1.5倍速|B・2倍速|A・1倍速|
|25|A・2倍速|B・1倍速|C・1.5倍速|
|26|A・2倍速|C・1倍速|B・1.5倍速|
|27|B・2倍速|A・1倍速|C・1.5倍速|
|28|B・2倍速|C・1倍速|A・1.5倍速|
|29|C・2倍速|A・1倍速|B・1.5倍速|
|30|C・2倍速|B・1倍速|A・1.5倍速|
|31|A・2倍速|B・1.5倍速|C・1倍速|
|32|A・2倍速|C・1.5倍速|B・1倍速|
|33|B・2倍速|A・1.5倍速|C・1倍速|
|34|B・2倍速|C・1.5倍速|A・1倍速|
|35|C・2倍速|A・1.5倍速|B・1倍速|
|36|C・2倍速|B・1.5倍速|A・1倍速|


被験者内実験計画（一人の被験者が3つの実験条件（1倍速，1.5倍速，2倍速）をすべて実施する実験計画）の場合には，この表にある組み合わせに対して一人ずつ被験者を割り当てることによって，全体としてバイアスを除去した実験が可能となる．

ただ，このような実験計画は被験者が最低でも36人必要となる．一方で，一人があくまで1つの条件しか経験しない形（被験者間実験計画）の実験条件であれば，被験者が全体として同質なのであれば，バイアス要因の相殺は考慮に入れる必要はない（動画を3種類も用意しなくてもよいし，実験順序という概念も存在しない）．したがって，被験者内計画にするか，被験者間計画にするかは，その時々での実験を実施できる環境に応じて選択するとよい．

</details>
:::

:::

