---
title: "基本的な検定"
author: "藤野秀則,"
date: 
  初版日:2024-05-02
  更新日:`r Sys.Date()`
output:
  html_document: 
    toc: true
    toc_depth: 4
    toc_float: true
    number_section: true
    fig_width: 8
    css: ./style.css

  # html_notebook:
  #   toc: true
  #   toc_depth: 3
  #   toc_float: true
  #   number_section: true
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# 平均の比較

## 比較の原理

2つのグループの間で平均を比較したい場合にはt検定というものを行う．これは厳密には**「2つのグループは元々は同じ母集団から抽出されたサンプルである」**という仮説（これを**帰無仮説**と呼ぶ）の元で，両グループの平均値の間に有意といえるほどの差があるかどうかを検定する手法である．

「元々同じ母集団である」という仮説の元では，理想的には両群の平均値は一致する，すなわち差は0になるはずである．実際にはデータにはばらつきは付きものなので，完全に0となることはないだろうが，差の値は0に近い値になる確率は高いだろし，0から遠い値になる確率は低いだろう．

そこで，実際に2つのグループのデータから、それぞれの平均値の差を求めたうえで，「2つのグループは同じ母集団から抽出されたサンプルである」という仮説のもとで，そのような差が出てくる確率はいくらであったかを算出する，というのがt検定の数学的な中身である．

そして，その確率が0.05，すなわち5%未満であったならば「2つは同じ母集団から抽出されたサンプルである」という仮定のもとでは極めて珍しい（発生確率が5%未満でしかない）値が出た，ということになる．ここで解釈の転換をして，「そんな珍しい値が出るなんてそうそうあることではない．そもそも元の仮説が誤っていたのではないか」と考える．つまり，「2つは同じ母集団から抽出されたサンプルである」という仮説を否定するのである．この仮説を否定するということは，「2つのグループは互いに性質の異なる（それゆえ母平均も異なる）母集団から抽出されたサンプルである」という仮説を支持する，ということである．こうして，2つのグループには「母集団のレベルで差がある」と主張するのがt検定である．

## t検定の方法（基本）

Rでt検定を行うには`t.test()`関数を用いる．この関数は、[平均の信頼区間](RText_04_DescriptiveStatistics.html#平均値の区間推定)で用いた関数であるが、本来は名前のとおりt検定を行う関数である．

第1引数と第2引数には比較したい2つのグループのデータをそれぞれ与える．いずれも**ベクトルデータ**で与える必要がある点に注意が必要である．


第3引数（省略可）には`alternative`のオプションを設定する．これは，「両側検定」を行うのか「片側検定」を行うのかの違いである．省略した場合，デフォルトとして「両側検定」が行われる．統計分析においては両側検定を行うのが一般的となっているため，ここは省略してもかまわない．


:::ref
<details>
<summary>両側検定と片側検定</summary>
両側検定は「データAの平均がデータBの平均に比べて有意に大きい」「データAの平均がデータBの平均に比べて有意に小さい」「両群に差があるとは言えない」という3つのいずれになるかを知りたい場合に用いる．

一方，片側検定では，事前に「データAの方がデータBに比べて大きい（小さい）はずである」ということが理論的に予想されている中で，「有意に大きい（小さい）」もしくは「大きい（小さい）といえない」という2つのいずれになるかを知りたい場合に用いる．

すなわち，片側検定では逆の結論は全く想定していないことになる．数学的には，両側検定の時に算出される確率（P値）はは片側検定のときのP値の2倍となる．すなわち，両側検定にした場合，有意になりにくくなる（5\%を上回りやすくなる）．このため，「有意になってほしい」という思いが強いと，片側検定にしたくなるが，片側検定をする場合，それを選択した理由をきちんと述べねばならない．

一般的には両側検定を用いることが多く，`t.test()`に限らず，Rで行う統計分析で有意検定を行っているものは**両側検定がデフォルトで実行される．**
</details>
:::

:::practice
ある農作物に与える肥料を新しく開発し，その効果を確かめるために，新しい肥料を与えた畝と通常の肥料を与えた畝を20ずつ用意し，それぞれの収穫量を測定した．その結果，次のようなデータ（[リンク](./practice/example_ttest.csv)）が得られた．このデータから新しい肥料を使用した場合に収穫量が向上するのかどうかを検証せよ．
:::

```{R eval=FALSE, include=FALSE}
# 再現性を確保するために乱数シードを設定
set.seed(42)

# データの個数
num_samples <- 20

# 通常の肥料を使用した場合の収穫量（平均50，標準偏差5）
normal_fertilizer_yield <- round(rnorm(num_samples, mean = 45, sd = 5),2)

# 新しい肥料を使用した場合の収穫量（平均55，標準偏差5）
new_fertilizer_yield <- round(rnorm(num_samples, mean = 55, sd = 5),2)

# データフレームの作成
data <- tibble(
  通常の肥料を使用 = normal_fertilizer_yield,
  新しい肥料を使用 = new_fertilizer_yield
)

# CSVファイルにデータを保存
write_csv(data, "./practice/example_ttest.csv")

```

この例題の場合，以下の通りとなる．
```{r}
mydata_ttest <- read.csv( # データ読み込み オブジェクト名は自由につけてよい
# データは以下の設定ではpracticeというフォルダに入っているコトになっているが，
# 特にそうしたフォルダに入れていない場合には ./example_ttest.csv とすればよい．
  "./practice/example_ttest.csv", 
  header=T, 
  fileEncoding = "UTF8"
)

# データの内容を確認
head(mydata_ttest)
# すべてのデータを見てみたければ
# 右上ペインのEvironmentのmydataをクリックするか，
# 以下のコマンドを実行．
# view(mydata)

# それぞれのデータを取得
新肥料 <- mydata_ttest$新しい肥料を使用
旧肥料 <- mydata_ttest$通常の肥料を使用


t.test(新肥料, 旧肥料)#Alternativeは省略　

```

2行目の`p-value = 0.0002922`という箇所が結果を示す箇所であり，また最後の
```{}
mean of x mean of y 
   53.645    45.960 
```
は，それぞれのデータの平均値である．この結果から，平均値としては約8の違いがあるのがわかる．

このデータではP値は0.05を下回ってり，「二つのグループは同じ母集団から抽出されたサンプルである」という帰無仮説を棄却された．すなわち，両者の平均は有意な違いがあるという結論となり，新しい肥料を用いることで収穫量の向上が望めることが示されたこととなる．

## 対応関係のあるデータでのt検定


対応関係とは，例えば2つのデータが「同じ人の1回目の測定と2回目の測定」というように，「同じサンプルから条件を変えて取得したデータ」である場合には，データの中で対応関係（ペア関係）が成立する．
このようなデータの場合には，**第4引数として, `paired = TRUE`というオプションを設定する必要がある**．

対応関係は，データの並びによってとられる．すなわち，

データ1の1つ目のデータ⇔データ2の1つ目のデータ<br/>
データ1の2つ目のデータ⇔データ2の2つ目のデータ<br/>
データ1の3つ目のデータ⇔データ2の3つ目のデータ<br/>
・・・<br/>

という対応関係がとられる．

なお，対応関係のあるデータでは，当然ながら二つのデータの点数は「同じ」であることが前提となる．
従って，`paired=TRUE`の設定をしている時に，一方のデータの中に`NA`が1つでも含まれていた場合には，`t.test()`はエラーを返してくる．
これを防ぐためには，さらに**na.rm=TRUEのオプション設定を行う**．
**このオプションを設定していた場合，一方のデータに`NA`が含まれていた場合，`NA`に対応したもう一方の値も除去される．**



:::practice
15人の協力者に，新しく試作した食パンと従来の食パンの食べ比べをしてもらい，おいしさを10段階で評価してもらったところ，次のようなデータ（[リンク](./practice/example_ttest_paired.csv)）が得られた．このデータをもとに，試作品と従来品とで美味しさの違いがあるのかを検証せよ．
:::

```{r eval=FALSE, include=FALSE}
# 再現性を確保するために乱数シードを設定
set.seed(42)

# データの個数
num_samples <- 15

# 従来の食パンの評価（平均6，標準偏差1.5）
traditional_bread_scores <- round(rnorm(num_samples, mean = 6, sd = 1.5),0)

# 新しい食パンの評価（平均7.5，標準偏差1.5）
new_bread_scores <- round(rnorm(num_samples, mean = 7.5, sd = 1.5),0)

# データフレームの作成
data <- tibble(
  従来品 = traditional_bread_scores,
  試作品 = new_bread_scores
)

# CSVファイルにデータを保存
write_csv(data, "./practice/example_ttest_paired.csv")
```

この例題の場合，**同じ人に対してデータを取っているため，二つのベクトルの間には対応関係が存在する**．このため，`paired`の設定が必要になる．は以下の通りとなる．

```{r}
mydata_ttest_paired <- read.csv(
  "./practice/example_ttest_paired.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み
# もしデータの内容を確認したければ，右上ペインのEvironmentのmydataをクリックするか，以下のコマンドを実行．
# view(mydata)

t.test(mydata_ttest_paired$従来品, mydata_ttest_paired$試作品, paired=TRUE, na.rm=T)

```
今回のデータの場合，p値は0.8123となっており，0.05を大きく上回っており，試作品と従来品とでおいしさに有意な差はない，という結論となる．
また，`paired`の設定をしたので，表題も`Paired t-test`となり，最後の結果も両群の平均値ではなく，群間の差のみが算出される．






## ロング形式データでのt検定

ロング形式のデータの場合でも，`filter()`を使って，分析に掛けるベクトルデータをそれぞれ取り出せば，基本のt検定の方法で分析ができる．
ただ，いちいち個別にベクトルデータを取りださなくても，**測定変数と属性変数を`~`（チルダ）で結んだ「式」**を`t.test()`関数の第1引数に与えることでも分析ができる．なお，属性変数のデータは要因型である必要がある．この場合，第2引数にはそれぞれの変数を含んだデータフレームのオブジェクト名を与える．

以下は例題1のデータをロング形式に変換したうえで，式形式でのt検定を行う例である．

```{r}
library(tidyverse) # pivot_longer関数を使うにはtidyverseを読み込む必要がある

# ロング形式のデータを作成
long_data <- pivot_longer(
  mydata_ttest,
  cols=colnames(mydata_ttest),
  names_to = "肥料",
  values_to= "収穫量" #測定変数に与える列名
)

# 肥料列を要因型に変換
long_data$肥料 <- as.factor(long_data$肥料)

# 内容確認
summary(long_data)

#t検定
t.test(収穫量~肥料, long_data)
```


<!-- (以下，2024.10.9追記) -->
「対応あり」データ(paired=TRUEとなるデータ）がロング形式のデータとなっている場合に，R 4.4.1（2024.10.9時点の最新，Posit Cloudはこちら）では，上記の例のように`式, data`形式を与える形での分析はできない．対応ありデータの場合には，以下の例のようにそれぞれのデータを取り出してt.testにかける必要がある．
<!-- （R 4.3.3であれば(式, data)形式でもpaired=TRUEの設定が可能）． -->

```{r error=TRUE}
## ロング形式のデータを作成
long_data_paired <- pivot_longer(
  mydata_ttest_paired,
  cols=colnames(mydata_ttest_paired),
  names_to = "食パン",
  values_to= "評価" #測定変数に与える列名
)

# 確認
long_data_paired$食パン <- as.factor(long_data_paired$食パン)
summary(long_data_paired)

# 以下の形式だとエラーになる．
t.test(評価~食パン, long_data_paired, paired=TRUE, na.rm=TRUE) 
 
# ロングデータからの食パンごとのデータを取り出し
data1 <- filter(long_data_paired, 食パン=="従来品")
data2 <- filter(long_data_paired, 食パン=="試作品")


# t検定
t.test(data1$評価, data2$評価, paired=TRUE)


```



## t検定の結果の報告方法
t検定の結果を報告する際には棒グラフを用いるのが一般的である（平均なので箱ひげ図は用いない）．二つの群の平均と標準偏差を棒グラフで表現したうえで，角傘（ブラケットと呼ぶ）をつけてp値を記載する．

<a name="推測統計量"/>

:::ref
t検定は，あくまでそのデータの違いを見ているのではなく，そのデータから推定される母集団に違いがあるかを検証するものである．このため，t検定の結果を報告する際に用いる統計量は，推測統計量となる．このことはt検定だけに限らず，あらゆる分析にあてはまる．今後解説していくあらゆる分析は得られているデータを基に推定される母集団の比較をしたり，母集団間の関係性を分析したりするものである．このため，**今後の分析の中で出てくる平均や標準偏差は全て基本的に推測統計量となる**．
:::


具体的にggplotを使って，先の2つの例題の結果を棒グラフで表記してみよう．まずは，[こちら](./RText_06_ggplot2_basicUsage.html#棒グラフ)のコードを参考に棒グラフを作成する．まずは例題1．
```{r}
library(ggplot2) # ggplotを使うためにはまずこのライブライを読み込んでおく必要がある

#まずは両群の平均と標準偏差を算出する．
mymean_new <- mean(mydata_ttest$新しい肥料を使用)
mymean_old <- mean(mydata_ttest$通常の肥料を使用)
mysd_new <- sd(mydata_ttest$新しい肥料を使用)
mysd_old <- sd(mydata_ttest$通常の肥料を使用)

mydf <- data.frame(
  条件=c("新しい肥料を使用", "通常の肥料を使用"),
  収穫量=c(mymean_new, mymean_old),
  標準偏差=c(mysd_new, mysd_old)
)

# ggplotで棒グラフを表示　
g <- ggplot(data=mydf)+ 
  geom_bar(aes(x=条件, y=収穫量, fill=条件), stat="identity")+
  geom_errorbar(aes(x=条件, ymin=収穫量-標準偏差, ymax=収穫量+標準偏差, width=0.1))
plot(g)
```

続いて，このグラフにブラケットをつけてp値を記載する．ブラケットをつけるためには，`annotate()`関数を用いて線分を描画する．この関数は第1引数として`"segment"`（線分の意味）を指定し，第2～４引数として始点と終点の座標を指定すると，その間に線分を描画する関数である．これを組み合わせてブラケットを描画する．x軸方向は「新しい肥料を使用」「通常の肥料を使用」というように数値ではなくラベルとなっているが，内部では座標として，それぞれ1，2とされているので，これを利用してブラケットを描画する．y座標については，エラーバーと干渉しないような値を設定してやる．以下では`y＝61, yend=64`としているが，別にこの値でなくてもよい．

```{r}
#エラーバーの上に実線を引く
g <- g + 
  annotate("segment",x=1, xend=1, y=61, yend=64)+
  annotate("segment",x=1, xend=2, y=64, yend=64)+
  annotate("segment",x=2, xend=2, y=61, yend=64)

plot(g)
```

さらに，これにp値を与える．これも`annotate()`関数を用いる．第1引数で`"text"`と指定して，`x`，`y`引数で座標（記載する文字列の中心位置）を指定し，`label`引数で表示する文字列を，`size`引数で文字の大きさを指定する．

```{r}
# 各傘の上に
g <- g+annotate("text",x=1.5, y=66, label="p=0.0002922, ***", size=3)
plot(g)
```

p値にはアスタリスクをつけるのが一般的である．アスタリスク（\*）の数はp値の大小に応じて変わる．**p値が0.05未満であれば1つ，0.01未満であれば2つ，0.001未満であれば3つとする**．

逆に有意でなかった場合には，P値を表記するだけで何も記載しないか，あるいは，`n.s.`と記載する．これは`not significant`の略であり，「有意でない」という意味である（さらに[多重比較](#多重比較)を行うケースでは有意でないものについてはブラケットも含め何も表記しないのが一般的である）．

また，上記の例のようにP値が0.000を下回っている場合には，桁を省略して，`P<0.001`と表記することもある．さらに，論文や報告書などでP値を文章中に明記している場合には，図ではP値を省略して，アスタリスクだけを記載することもある．

例題2の方でも同様に棒グラフを作成してみよう．今度は描画関数をすべてまとめて記載する．
```{r}
#まずは両群の平均と標準偏差を算出する．
mymean_new <- mean(mydata_ttest_paired$試作品)
mymean_old <- mean(mydata_ttest_paired$従来品)
mysd_new <- sd(mydata_ttest_paired$試作品)
mysd_old <- sd(mydata_ttest_paired$従来品)

# データフレームの作成
mydf <- data.frame(
  条件=c("試作品", "従来品"),
  おいしさ=c(mymean_new, mymean_old),
  標準偏差=c(mysd_new, mysd_old)
)

# ggplotで棒グラフを表示
g<- ggplot(data=mydf)+ 
  geom_bar(aes(x=条件, y=おいしさ, fill=条件), stat="identity")+
  geom_errorbar(aes(x=条件, ymin=おいしさ-標準偏差, ymax=おいしさ+標準偏差, width=0.1))+
  annotate("segment",x=1, xend=1, y=9, yend=10)+
  annotate("segment",x=1, xend=2, y=10, yend=10)+
  annotate("segment",x=2, xend=2, y=9, yend=10)+
  annotate("text",x=1.5, y=10.5, label="p=0.8123, n.s.", size=5)
plot(g)

```



なお，ロング型のデータの場合には，[こちら](./RText_04_DescriptiveStatistics.html#グループごとの統計量の算出)で説明した通り，平均や標準偏差は`aggregate()`関数を用いて算出するとよい．以下これらを使って棒グラフを表示させる．

```{r}
# 平均値の算出
平均<-aggregate(収穫量~肥料, long_data, mean)
# 標準偏差の算出
標準偏差<-aggregate(収穫量~肥料, long_data, sd)

#データフレームの作成
mydf <- data.frame(
  条件=平均$肥料,
  収穫量=平均$収穫量,
  標準偏差=標準偏差$収穫量
)

# ggplotで棒グラフを表示
g<- ggplot(data=mydf)+
  geom_bar(aes(x=条件, y=収穫量, fill=条件), stat="identity")+
  geom_errorbar(aes(x=条件, ymin=収穫量-標準偏差, ymax=収穫量+標準偏差, width=0.1))+
  annotate("segment",x=1, xend=1, y=61, yend=64)+
  annotate("segment",x=1, xend=2, y=64, yend=64)+
  annotate("segment",x=2, xend=2, y=61, yend=64)+
  annotate("text",x=1.5, y=66, label="p=0.0002922, ***", size=4)
plot(g)
```


:::work
ある自治体の高校生を対象に朝食摂取と成績の関係を明らかにするために調査をおこない，このような[データ](./practice/07_work_1.csv)を取得した．この調査では，調査日（抜き打ち実施）に朝食を食べているかどうかと，4限目の授業で実施した数学のテストの得点がデータとして取得されている．このデータについて，以下の課題を実施せよ．

1. このデータの冒頭6行分をhead()を用いて確認し，このデータがワイド形式かロング形式か確認せよ．
1. 摂取群と欠食群のそれぞれの平均と標準偏差（[こちら](#推測統計量)で述べている通り推測統計量でよい）を算出するとともに，それらを棒グラフで示せ．棒グラフにはエラーバーも付与すること．
1. 朝食を食べている人と食べていない人とで数学のテストの得点に有意な差があるかどうかを検証せよ．
1. 先に描いた棒グラフ上にt検定の結果を示すブラケットを書き入れよ．

```{r include =F}
set.seed(42)

# データの個数
num_samples <- 4000
result <- sample(c("摂取", "欠食"), num_samples, replace = TRUE, prob = c(0.72, 0.38))
score <- round(rnorm(num_samples, mean = 50, sd = 10),0)

library(tidyverse)
weight <- ifelse(result == "摂取", 3, 0)
data <- tibble(
  朝食 = result,
  得点 = score+weight
)

write.csv(data, "./practice/07_work_1.csv")
```


```{r include=FALSE}
mydata_work1 <- read.csv(
  "./practice/07_work_1.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

# 1. データの確認
head(mydata_work1)

# 2. 平均と標準偏差の算出
平均<-aggregate(得点~朝食, mydata_work1, mean)
標準偏差<-aggregate(得点~朝食, mydata_work1, sd)

#データフレームの作成
mydf <- data.frame(
  条件=平均$朝食,
  得点=平均$得点,
  標準偏差=標準偏差$得点
)

# ggplotで棒グラフを表示
g<- ggplot(data=mydf)+
  geom_bar(aes(x=条件, y=得点, fill=条件), stat="identity")+
  geom_errorbar(aes(x=条件, ymin=得点-標準偏差, ymax=得点+標準偏差, width=0.1))
plot(g)

# 3. t検定
t.test(得点~朝食, mydata_work1)

# 4. ブラケットの追加
g<- ggplot(data=mydf)+
  geom_bar(aes(x=条件, y=得点, fill=条件), stat="identity")+
  geom_errorbar(aes(x=条件, ymin=得点-標準偏差, ymax=得点+標準偏差, width=0.1))+
  annotate("segment",x=1, xend=1, y=68, yend=70)+
  annotate("segment",x=1, xend=2, y=70, yend=70)+
  annotate("segment",x=2, xend=2, y=70, yend=68)+
  annotate("text",x=1.5, y=73, label="p=2.2*10^-16, ***", size=4)
plot(g)
```

:::

:::work
あるショコラティエで，新しいチョコレートの試作に取り組んでいる．同じチョコレートでも，どのような形に成形するかで，味の評価が変わるのではないかと考え，店に来店したお客さん50人にそれぞれを食べてもらい，おいしさを10段階で評価してもらい，次のような[データ](./practice/07_work_2.csv)を取得した．このデータについて，以下の課題を実施せよ．

1. このデータの冒頭6行分をhead()を用いて確認し，このデータがワイド形式かロング形式か確認せよ．
1. 形状Aと形状Bのそれぞれの平均と標準偏差を算出するとともに，それらを棒グラフで示せ．棒グラフにはエラーバーも付与すること．
1. 形状Aと形状Bとでおいしさに有意な差があるかどうかを検証せよ．
1. 先に描いた棒グラフ上にt検定の結果を示すブラケットとt検定の結果えられた有意確率を書き入れよ．

```{r include =F}
set.seed(23)

# データの個数
library(truncnorm)
num_samples <- 50
score_A <- round(rtruncnorm(num_samples, a=0, b=10, mean = 6, sd = 1.5),0)
score_B <- round(rtruncnorm(num_samples, a=0, b=10, mean = 7, sd = 2.5),0)

data <- tibble(
  No. = 1:num_samples,
  形状A = score_A,
  形状B = score_B
)

write.csv(data, "./practice/07_work_2.csv")
```

```{r include=FALSE}
mydata_work2 <- read.csv(
  "./practice/07_work_2.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

# 1. データの確認
head(mydata_work2)

# 2. 平均と標準偏差の算出
平均<-c(mean(mydata_work2$形状A), mean(mydata_work2$形状B))
標準偏差<-c(sd(mydata_work2$形状A), sd(mydata_work2$形状B))

#データフレームの作成
mydf <- data.frame(
  条件=c("形状A", "形状B"),
  おいしさ=平均,
  標準偏差=標準偏差
)
print(mydf)

#グラフ
g<-ggplot(mydf)+
  geom_bar(aes(x=条件, y=おいしさ, fill=条件), stat="identity")+
  geom_errorbar(aes(x=条件, ymin=おいしさ-標準偏差, ymax=おいしさ+標準偏差, width=0.1))
plot(g)

# t検定
A <- mydata_work2$形状A
B <- mydata_work2$形状B
t.test(A, B, paired=TRUE)

# ブラケットの追加
g<-ggplot(mydf)+
  geom_bar(aes(x=条件, y=おいしさ, fill=条件), stat="identity")+
  geom_errorbar(aes(x=条件, ymin=おいしさ-標準偏差, ymax=おいしさ+標準偏差, width=0.1))+
  annotate("segment",x=1, xend=1, y=9, yend=9.5)+
  annotate("segment",x=1, xend=2, y=9.5, yend=9.5)+
  annotate("segment",x=2, xend=2, y=9, yend=9.5)+
  annotate("text",x=1.5, y=9.7, label="p=0.02258, *", size=4)
plot(g)
```
:::


# 分散の比較

先ほどは2つのグループの間での平均の比較，すなわち「2つのグループの間で平均値の差が意味のある差なのか誤差の範囲に収まる差なのか」を検証する方法について説明した．次に，2つのグループの間で「ばらつき」，すなわち分散に違いがあるのかどうかを検定する方法について説明する．

分散の場合には「差」をとるのではなく，「比率」（すなわち割り算をする）をとることになる．すなわち，2つのグループの分散の比率を求め，それが1（すなわち等しい）かどうかを検定することになる．この検定方法はF検定と呼ばれる．

分散の比較における**帰無仮説は「2つの群の母集団の分散は等しい」**となる．この帰無仮説が棄却された場合，すなわちP値が有意水準を下回った場合，「2つの群の母集団の分散は等しくない」と結論づけることができる．

:::ref
分散の比較においては，「対応のあるデータ」についての検定は行わない．その理由として，対応のあるデータでは，「群の分散」よりも「それぞれのペアごとの差の平均」が重要（差の平均の母数が0となるか）であるためであり，各群を別個に捉えて分散を比較することに意味はないからである．
:::


## F検定の方法（基本）
F検定は，Rの`var.test()`関数を用いて行う．この関数は，第1引数と第2引数に比較したい2つのグループのデータを与える．この関数は，t検定と同様に「2つのグループは同じ母集団から抽出されたサンプルである」という仮説の元で，2つのグループの分散の比率が1であるかどうかを検定する．

:::practice
ある製品の製造工程を変更したところ，製品の重量にばらつきが生じた．このばらつきが工程変更の影響によるものなのか，単なる偶然によるものなのかを検証するために，工程変更前と工程変更後の製品の重量を測定した．その結果，次のようなデータ（[リンク](./practice/example_vartest.csv)）が得られた．このデータから工程変更によるばらつきの変化があるのかを検証せよ．
:::

```{r include=FALSE}
#./practice/example_vartest.csvの作成
set.seed(42)
num_samples <- 20
before_change <- round(rnorm(num_samples, mean = 100, sd = 5),2)
after_change <- round(rnorm(num_samples, mean = 100, sd = 10),2)
data <- tibble(
  工程変更前 = before_change,
  工程変更後 = after_change
)

write_csv(data, "./practice/example_vartest.csv")
```

Rのスクリプトは以下の通りとなる．

```{r}
mydata_vartest <- read.csv(
  "./practice/example_vartest.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

変更前 <- mydata_vartest$工程変更前
変更後 <- mydata_vartest$工程変更後
var.test(変更前, 変更後)

```

この結果から，P値が0.02となっており，5％の有意水準を下回っているため，工程変更によって製品の重量のばらつきに有意な変化が生じたと結論づけることができる．


## ロング形式のデータでのF検定

ｔ検定の時と同様に，ロング形式のデータの場合には`測定変数~要因変数, データ`の形でも検定を行うことができる．以下にその例を示す．

```{r}
#ワイド形式からロング形式に変換
long_data_vartest <- pivot_longer(
  mydata_vartest,
  cols=colnames(mydata_vartest)[],
  names_to = "工程",
  values_to= "重量" #測定変数に与える列名
) 

# 工程を要因型（要因型）に変換
long_data_vartest$工程 <- as.factor(long_data_vartest$工程)

# F検定の実施
var.test(重量~工程, long_data_vartest)
```

## F検定の結果の報告方法
F検定の結果を報告する際には，一般には棒グラフを用いることは少ない．F検定の結果は，P値が有意水準を下回っているかどうかを確認するだけでよい．P値が有意水準を下回っている場合には「2つの群の分散は5%の有意水準のもとで有意な違いがある（F(`df1`, `df2`)=`F-Value`, P=`value`）」と記載する．`df1`と`df2`はそれぞれの2つの群の自由度（各群のサンプル数―1）を示し，`F-Value`はF値を示す．

例えば，上の例題の場合には，「工程変更前と工程変更後の製品の重量の分散に有意な違いがあることが示された（F(19, 19)=4.5, P=0.02）．」と記載する．

:::work
ある製品メーカでは，製品の歩留まり率（検品の際に不良品として弾かれ**なかった**製品の割合）の向上を狙って，製造工程を変更した．この工程変更によって，製品の品質のバラツキが抑えられたかどうかを検証するために，変更前の製造された製品の品質検査（100点満点）と変更後の製品の品質検査の結果をランダムに200個ずつ取り出してきた．この[データ](./practice/07_work_3.csv)から工程変更による品質のバラツキに変化があるのかを検証するために，以下のことを行え．

1. このデータの冒頭6行分をhead()を用いて確認し，このデータの形式か確認せよ．
1. 変更前と変更後のそれぞれの平均と標準偏差を算出するとともに，それらを棒グラフで示せ．棒グラフにはエラーバーも付与すること．
1. 変更前と変更後とで品質検査の点数そのものに有意な差があるかどうかを検証せよ．
1. 変更前と変更後とで品質検査の点数のバラツキに有意な差があるかどうかを検証せよ．
:::

```{r include =F}
set.seed(42)

# データの個数
num_samples <- 200
before_change <- round(truncnorm::rtruncnorm(num_samples, a=0, b=100, mean = 70, sd = 10),0)
after_change <- round(truncnorm::rtruncnorm(num_samples, a=0, b=100, mean = 70, sd = 5),0)

data <- tibble(
  変更前 = before_change,
  変更後 = after_change
)

write.csv(data, "./practice/07_work_3.csv")
```

```{r include=FALSE}
mydata_work3 <- read.csv(
  "./practice/07_work_3.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

# 平均と標準偏差
平均<-c(mean(mydata_work3$変更前), mean(mydata_work3$変更後))
標準偏差<-c(sd(mydata_work3$変更前), sd(mydata_work3$変更後))

#データフレームの作成
mydf <- data.frame(
  条件=c("変更前", "変更後"),
  品質検査=平均,
  標準偏差=標準偏差
)
print(mydf)

#グラフ
g<-ggplot(mydf)+
  geom_bar(aes(x=条件, y=品質検査, fill=条件), stat="identity")+
  geom_errorbar(aes(x=条件, ymin=品質検査-標準偏差, ymax=品質検査+標準偏差, width=0.1))
plot(g)

# t検定
t.test(mydata_work3$変更前, mydata_work3$変更後)

# F検定
var.test(mydata_work3$変更前, mydata_work3$変更後)

```



# 独立性の検定
続いて比率の比較を行う方法を説明する．比率の検定とは，例えば以下の表のような「クロス集計表」が作られている時に，列方向に並べた属性変数Aと行方向に並べた属性変数Bが互いに独立しているのか，何等かの関係性があるのかを検定する方法である．**帰無仮説は「互いに独立している」**であり，それが否定することによって「関係性がある」と結論づける統計方法である．

|  | Bあり | Bなし | 合計 |
|---|---|---|---|
| Aあり | 10 | 20 | 30 |
| Aなし | 20 | 60 | 80 |
| 合計 | 30 | 80 | 110 |

## 「独立」とは？

ここで，独立とは，たとえば上記の表の場合，条件Aが「あり」の場合での条件Bの「あり」と「なし」の比率は1:2であるが，条件Aが「なし」の場合での条件Bの「あり」と「なし」の比率も1:2である．すなわち，条件Aが「あり」か「なし」かによって，条件Bの「あり」か「なし」かのなり易さ（生起確率）に違いはない．このような場合には，**条件Aと条件Bが互いに独立している**と呼ぶ．

逆に以下の表のような場合，条件Aが「あり」の場合での条件Bの「あり」と「なし」の比率は1:2であるが，条件Aが「なし」の場合での条件Bの「あり」と「なし」の比率は1:6である．すなわち，条件Aが「あり」か「なし」かによって，条件Bの「あり」か「なし」かの生起確率が異なっている．このような場合には，条件Aと条件Bが互いに独立していないと呼ぶ．

|  | Bあり | Bなし | 合計 |
|---|---|---|---|
| Aあり | 10 | 20 | 30 |
| Aなし | 10 | 60 | 70 |
| 合計 | 20 | 80 | 100 |

実際には，誤差が入り込むので，完全に比率が等しくなるということはほとんどなく，「独立」とみなされる範囲には幅がある．では，実際に何らかのクロス集計表がえられたときに，比率にどの程度以上の差があれば「独立していない＝関連性がある」とみなすのか？その検定を行うのが独立性の検定である．

## カイ2乗検定とフィッシャーの正確確率検定

独立性の検定では，一般にカイ2乗($\chi^2$)検定というものを用いる．ただし，カイ2乗検定はクロス集計した際の**いずれかのセルが5未満の値の場合には正確な値は返してこない場合がある**．そこでそうしたケースでも対応できるような方法としてFisherの正確確率検定というものがある．以下では，カイ2乗検定とFisherの正確確率検定の両方の方法について説明する．

###カイ2乗検定の方法
カイ2乗検定は，Rの`chisq.test()`関数を用いて行う．この関数は，以下の2通りの方法で実行可能である．

1. 1つは，第1引数に要因Aについてのベクトルデータ，第2引数に要因Bについてのベクトルデータを与える
1. クロス集計したテーブルデータを引数とする．

通常，比率の検定を行う際にはその前段でクロス集計を行うのが一般的なので，後者の場合だとその結果をそのままつかうことができる．

クロス集計表の作成は，Rの`table()`関数を用いて行う．この関数は，第1引数に要因Aについてのベクトルデータ，第2引数に要因Bについてのベクトルデータを与えると，クロス集計表を作成してくれる．なお，要因Aと要因Bは当然ながら対応あるデータであることが前提である．また，**要因A，要因Bにそれぞれ与えるベクトルデータは要因型**である必要がある．

なお，ここで用いられている要因A，要因Bの各ベクトルデータは互いに対応関係があるデータである．すなわち，例えば要因Aのベクトルの1つ目のデータと要因Bの1つ目のデータは同じサンプルが取られたデータである，ということである．このように対応関係がデータの並びによって取られていくので，分析を掛けるにあたっては，各ベクトルのデータの並びがきちんと合っているかを注意しておく必要がある．．

:::practice
ある試験を受験した100人の受験者について，性別(男性, 女性）と合否（不合格, 合格）のデータ（[リンク](./practice/example_chisq.csv)）がある．このデータから，クロス集計表を作成するとともに，性別と合否の間に関連性があるのかどうかを検証せよ．
:::

```{r include=FALSE}
#./practice/example_chisq.csvの作成
set.seed(42)
num_samples <- 100
性別 <- rbinom(num_samples, 1, 0.5)
合否 <- rbinom(num_samples, 1, 0.4)
性別 <- recode(性別, `0`="男性", `1`="女性")
合否 <- recode(合否, `0`="不合格", `1`="合格")
data <- tibble(
  性別 = 性別,
  合否 = 合否,
)
write_csv(data, "./practice/example_chisq.csv")

```

Rのスクリプトは以下の通りとなる．

```{r}
mydata_chisq <- read.csv(
  "./practice/example_chisq.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

# 要因型に変換
mydata_chisq$合否 <- as.factor(mydata_chisq$合否)
mydata_chisq$性別 <- as.factor(mydata_chisq$性別)

# データの確認
head(mydata_chisq)
summary(mydata_chisq)

#クロス集計表の作成 
# クロス集計表にはtable()関数を用いる.引数には行，列に割り振りたい要因を与える．
# 以下のように引数に名前を与えることもできる．
cross_table <- table("性別"=mydata_chisq$性別, "合否"=mydata_chisq$合否)
cross_table

#カイ二乗検定
## 要因Aと要因Bをそれぞれベクトルデータとして与える．
chisq.test(mydata_chisq$性別, mydata_chisq$合否)
chisq.test(cross_table)
```
この結果から，P値が0.6284となっており，5%の有意水準を下回っていないため，性別と合否の間に有意な関連性があるとは言えない．すなわち，性別は入試の合否に対して「独立である」（影響を与えていない）という可能性が否定出来ないという結果となった．


### Fisherの正確確率検定の方法
Fisherの正確確率検定は，Rの`Fisher.test()`関数を用いて行う．引数の与え方は`chisq.test`と同様に2通りの方法が可能である．

:::practice
ある喫茶店でコーヒーを注文したかどうか（しなかった，した）と，スイーツを注文したかどうか（しなかった，した）のデータ（[リンク](./practice/example_fisher.csv)）がある．このデータから，クロス集計表を作成するとともに，コーヒーを注文するかどうかとスイーツを注文するかどうかの間に関連性があるのかどうかを検証せよ．
:::

```{r include=FALSE}
#./practice/example_fisher.csv
set.seed(2)
num_samples <- 50
珈琲 <- c(rep(1,35),rep(0,15))
甘味 <- c(rbinom(35, 1, 0.6),rbinom(15, 1, 0.1))
珈琲 <- recode(珈琲, `0`="しなかった", `1`="した")
甘味 <- recode(甘味, `0`="しなかった", `1`="した")
data <- tibble(
  珈琲 = 珈琲,
  甘味 = 甘味,
)
write_csv(data, "./practice/example_fisher.csv")

```

Rのスクリプトは以下の通りとなる．

```{r}
mydata_fisher <- read.csv(
  "./practice/example_fisher.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

mydata_fisher$珈琲 <- as.factor(mydata_fisher$珈琲)
mydata_fisher$甘味 <- as.factor(mydata_fisher$甘味)
summary(mydata_fisher)

#クロス集計表の作成
cross_table <- table("珈琲"=mydata_fisher$珈琲, "甘味"=mydata_fisher$甘味)
cross_table

```
この結果から，スイーツもコーヒーも注文していない人が3人しかいないためカイ2乗検定では対応できないデータとなっている．
このため，フィッシャーの正確確率検定を行う．

```{r}
#Fisherの正確確率検定
fisher.test(mydata_fisher$珈琲, mydata_fisher$甘味)
fisher.test(cross_table)
```


P値が0.0049となっており，1%の有意水準を下回っているため，コーヒーを注文するかしないかとスイーツを注文するかしないかの間に有意な関連性があると結論づけることができる．

## カイ2乗検定とFisherの正確確率検定の使い分け
上記の通り，一般にいずれかのセルが5未満の小さな値になっている場合には，カイ2乗検定では正しい結果が導けなくなるので，Fisherの正確確率検定が良い，と述べた．であるならば，どのような場合でもFisherの正確確率検定を用いればよいではないか，という意見が出てくるだろう．

確かにFisherの正確確率検定を常に用いれば，カイ2乗検定の問題を回避できる．しかし，Fisherの正確確率検定は，カイ2乗検定に比べて計算量が多く，計算時間がかかるというデメリットがある．この時間はデータのサンプル数に依存しており，サンプル数が大きい場合には計算規模が大きくなりすぎてアプリケーションがフリーズしたり，あるいはRの側でエラーを返してくることもある．そのため，データの規模が大きい場合には，カイ2乗検定を用いることが一般的である．

実際にどれくらいのサンプル数であればカイ2乗検定の方が良いかの目安というものは特には存在しないので，サンプル数が5以上なのであれば，一旦はFisherの正確確率検定を実施してみて，もし何らかの問題が発生すればカイ2乗検定に切り替える，という方針が良いだろう．


## 結果の報告方法
クロス集計表の結果を報告する際には，まずはクロス集計表をしめす．その上で，カイ2乗検定を使った場合，「カイ2乗検定の結果2つの群の間に有意な関連性があることが確認された（$\chi^2$(`df`)=`X-squared`, P=`p-value`）」と文章の中で記載する．`df`は自由度を示し，`X-squared`はカイ2乗値を，`p-value`はP値を示す．一方，フィッシャーの正確確率検定の場合には，「フィッシャーの正確確率検定の結果2つの群の間に有意な関連性があることが確認された（P=`p-value`）」と記載する．

## 3つ以上の水準を持つ要因での独立性の検定
上記の例では，2つの水準を持つ要因同士（つまりクロス集計表が$2 \times 2$となる）での独立性の検定を行ったが，3つ以上の水準を持つ要因での独立性の検定も同様に行うことができる．その場合には，クロス集計表を作成する際には，`table()`関数によって作成したクロス集計表をそのまま`chisq.test()`関数や`fisher.test()`関数に与えることで検定を行うことができる．

:::practice
ある大学の食堂の利用頻度が学部によって異なるのではないかという疑問が生じた．そこで，ある大学の学生に対して，学部（文学部，理学部，工学部）と食堂の利用頻度（毎日，週に3回以上，週に1回以上，月に1回以上，年に1回以上，利用しない）について尋ねるアンケートを行った．その結果，次のようなデータ（[リンク](./practice/example_Restaurant.csv)）が得られた．このデータから，学部と食堂の利用頻度の間に関連性があるのかを検証せよ．
:::

```{r include=FALSE}
#./practice/example_Restaurant.csvの作成
set.seed(42)

文学部 <- sample(c("毎日", "週に3回以上", "週に1回以上", "月に1回以上", "年に1回以上", "利用しない"), 200, replace = TRUE, prob=c(0.1, 0.1, 0.2, 0.3, 0.2, 0.1))

理学部 <- sample(c("毎日", "週に3回以上", "週に1回以上", "月に1回以上", "年に1回以上", "利用しない"), 400, replace = TRUE, prob=c(0.4, 0.3, 0.1, 0.1, 0.05, 0.05))

工学部 <- sample(c("毎日", "週に3回以上", "週に1回以上", "月に1回以上", "年に1回以上", "利用しない"), 700, replace = TRUE, prob=c(0.7, 0.2, 0.05, 0.05, 0.025, 0.025))

data <- tibble(
  学部 = c(rep("文学部", 200), rep("理学部", 400), rep("工学部", 700)),
  食堂利用頻度 = c(文学部, 理学部, 工学部)
)

data<- data[sample(nrow(data)),]

write.csv(data, "./practice/example_Restaurant.csv")
```

```{r error=T}
mydata_restaurant <- read.csv(
  "./practice/example_Restaurant.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

mydata_restaurant$学部 <- as.factor(mydata_restaurant$学部)
mydata_restaurant$食堂利用頻度 <- as.factor(mydata_restaurant$食堂利用頻度)
summary(mydata_restaurant)

#クロス集計表の作成
cross_table <- table(mydata_restaurant$学部, mydata_restaurant$食堂利用頻度)
cross_table

# カイ2乗検定
chisq.test(cross_table)
```
この結果から，P値が$2.2 \times 10^{-16}$未満という非常に小さな値となっており，有意水準を裕に下回っているため，学部と食堂の利用頻度の間に有意な関連性がある，すなわち，学部によって職宇利用頻度は異なると結論づけることができる．

このように3つ以上の水準を持つ要因での独立性も，chisq.test()で検証することができる．


ちなみ，このデータをfisher.testで行った場合には以下の通りエラーが出力される．

```{r error=T}
fisher.test(cross_table)
```

これは計算量が膨大になり，計算のためのメモリ領域(エラーメッセージのworkplace)が足りないことによって生じたエラーである．メッセージにあるとおり，以下の例の通り，workplaceに大きな数字を設定してやれば（以下の例では2e9=$2\times 10^9$という膨大な大きさのメモリを設定している），計算させることができるがかもしれないが，計算できたとして膨大な計算時間がかかってしまうだろう．

```{r eval=F}
fisher.test(cross_table, workspace=2e9)
```

サンプル数が大きい場合にはカイ2乗検定でも十分に正確な結果が出力されるので，chisq.testで十分である．




:::work
ある大学3年生の学生が，最近後輩たちが使っているメッセンジャーアプリに違いが出てきているように感じている．具体的には，自分達はLINEを主なメッセンジャーツールとして使っているが，最近の後輩はInstagramのDMを主なツールとして使っているようだ．そこで実際に自分達の世代と後輩世代と使っているメッセンジャーアプリに違いがあるのかをゼミ研究として調査をしてみることにした．

調査は，大学1から4年生の学生約2000人に対して，LINEとInstagramのどちらを主なメッセンジャーツールとして使っているかを尋ねるアンケートをメールで送付した．結果，次のようなデータ（[リンク](./practice/07_work_4.csv)）が得られた．このデータから，先輩群(3，4年生）と後輩群(1，2年生）の間で使っているメッセンジャーアプリに違いがあるのかを検証せよ．
:::

```{r include=FALSE}
#./practice/07_work_4.csvの作成
set.seed(42)
num_samples_Elder <- 321
num_samples_Younger <- 535

SNS_Elder <- sample(c("LINE", "Instagram"), num_samples_Elder, replace = TRUE, prob=c(0.7, 0.3))
SNS_Younger <- sample(c("LINE", "Instagram"), num_samples_Younger, replace = TRUE, prob=c(0.4, 0.6))

data <- tibble(
  年代 = c(rep("先輩", num_samples_Elder), rep("後輩", num_samples_Younger)),
  SNS = c(SNS_Elder, SNS_Younger)
)

shuffled_df <- data[sample(nrow(data)), ]

write.csv(shuffled_df, "./practice/07_work_4.csv")
```

```{r include=FALSE}
mydata_work4 <- read.csv(
  "./practice/07_work_4.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

mydata_work4$年代 <- as.factor(mydata_work4$年代)
mydata_work4$SNS <- as.factor(mydata_work4$SNS)
summary(mydata_work4)

#クロス集計表の作成
cross_table <- table(mydata_work4$年代, mydata_work4$SNS)
cross_table

# Fisherの正確確率検定
chisq.test(cross_table)

```

:::work
ある大学のあるゼミの学生が，ふと「政治学のゼミにいる学生はそのほかのゼミの学生より．選挙に行く人が多いのだろうか」という疑問を抱いた．これを検証するために，実際に最近あった衆議院選挙に投票に行ったかどうかを尋ねるアンケートを行った．その結果，次のようなデータ（[リンク](./practice/07_work_5.csv)）が得られた．このデータから，政治学ゼミの学生とその他のゼミの学生の間で投票に行く人の割合に違いがあるのかを検証せよ．
:::

```{r include=FALSE}
set.seed(32)
num_samples_Political <- 15
num_samples_Other <- 180

Voting_Political <- sample(c("Yes", "No"), num_samples_Political, replace = TRUE, prob=c(0.75, 0.25))
Voting_Other <- sample(c("Yes", "No"), num_samples_Other, replace = TRUE, prob=c(0.45, 0.55))

data <- tibble(
  ゼミ = c(rep("政治学", num_samples_Political), rep("その他", num_samples_Other)),
  投票 = c(Voting_Political, Voting_Other)
)

#シャッフル
shuffled_df <- data[sample(nrow(data)), ]

write.csv(shuffled_df, "./practice/07_work_5.csv")

```

```{r include=FALSE}
mydata_work5 <- read.csv(
  "./practice/07_work_5.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

mydata_work5$ゼミ <- as.factor(mydata_work5$ゼミ)
mydata_work5$投票 <- as.factor(mydata_work5$投票)
summary(mydata_work5)

#クロス集計表の作成
cross_table <- table(mydata_work5$ゼミ, mydata_work5$投票)
cross_table

# Fisherの正確確率検定
fisher.test(cross_table)

```






# 比率の差の検定
独立性の検定と類似したものとして「比率の差の検定」というものもある．独立性の検定が要因Aと要因Bのクロス集計表から，**AとBの間に関連性があるかどうか**を検証するのに対して，比率の差の検定は，要因Aの2つの水準（例えば，男性と女性）の間で，それぞれの中での何らかの属性水準の占める割合（例えば，合格率＝受験者に占める合格者の割合）の差が有意であるかどうかを検証するものである．この場合にはZ検定を用いる．

比率の差の検定における**帰無仮説は「2つの水準間で比率に差がない」**である．

## Z検定の方法

RでZ検定を行う場合には`prop.test()`関数を用いて行う．
この関数は，第1引数に，比較したい2つのグループの成功数，第2引数に，比較したい2つのグループの試行総数を与る．

先ほどの合否の例で男女での合格率に差があるかを検証してみよう．第1引数には，今回だと男女それぞれの合格者数をベクトルで与え，第2引数には，男女それぞれの受験者数をベクトルで与えることになる．

このためまずは男女別の受験者数と合格者数を求める必要がある．
`filter()`関数と`length()`（ベクトルデータの要素数を返す）や`nrow()`（データフレームの行数＝サンプル数を返す）を用いてデータを抽出することで求めることもできるが，Rには条件に合うデータの数を返す関数として`sum()`関数というものが用意されているのでそれを用いると良い．


```{r}
mydata_chisq <- read.csv(
  "./practice/example_chisq.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

mydata_chisq$合否 <- as.factor(mydata_chisq$合否)
mydata_chisq$性別 <- as.factor(mydata_chisq$性別)
summary(mydata_chisq)

# sum関数は条件に合うデータの数を返す関数
男合格<-sum(mydata_chisq$性別=="男性" & mydata_chisq$合否=="合格")
# 以下の書き方をしてもよい．
# d_m_s<- filter(mydata_chisq, 性別=="男性" & 合否=="合格") 
# 男合格<- nrow(d_m_s)

#男性0の総数
男総数<-sum(mydata_chisq$性別=="男性")
# d_m<- filter(mydata_chisq, 性別=="男性")
# 男総数<- nrow(d_m)


#女性の合格の数
女合格<-sum(mydata_chisq$性別=="女性" & mydata_chisq$合否=="合格")
#女性の総数
女総数<-sum(mydata_chisq$性別=="女性")
```

以上のようにして男女別の合格者数, 受験者数が求まったので，これらを使ってprop.test()関数を実行する．

```{r}
# それぞれの成功数と試行数をベクトルにする わかりやすさのため名前付きベクトルにしておく
success <- c(男性合格者=男合格, 女性合格者=女合格) 
total <- c(男性受験者=男総数, 女性受験者=女総数)
# 確認のためそれぞれの合格率を算出
print(success/total)

# Z検定
prop.test(success,total)
```

結果として，男性と女性で合格率には有意な差はない，という結果となった．

なお有意確率を見ると，実は先の独立性の検定でのchisq.testの出力結果と同じ値となっている．
これは，特に今回のように$2\times 2$のクロス集計が可能である場合，比率の差に有意な差があるかないかと，要因間の関連性があるかどうかという検定が，数学的には同じであるためである．

ただし，3つ以上の水準を持つ要因を分析対象としている場合（すなわち，$3\times 2$以上のクロス集計となる場合）には，独立性の検定においては，先にも述べた通り，水準すべてを考慮したうえで，全体として独立か，関連性があるのかを検定することになる一方，比率の差の検定の場合は，「差」というものはそもそも**2つのものの間での比較**でなので，3つ以上の水準を含んだ要因を分析対象にしていた場合でも，それらの要因の中のどの水準とどの水準を比べるのか，という話になる．

例えば，ある要因でA, B, Cという群分けをして，合格率を比べる，という場合，全体として群分けと合格率に関係があるか，ということを調べたいのであれば，独立性の検定であり，[こちら](#3つ以上の水準を持つ要因での独立性の検定)で述べた通りにカイ2乗検定を掛ける．一方で，各群の間での合格率の差が有意であるかどうかを調べたい，という場合にはA-B，B-C，C-Aという3つの組み合わせのそれぞれでZ検定を行う，ということになる（なお，この場合，次に述べる「多重性問題」への対応が必要になる）．


# 多重比較

例えば以下のようなケースではどのような分析をすればよいだろうか．

:::practice
あるオンライン小売業者が，新しい広告キャンペーンを展開する際，3つの異なる広告バナーを作成した．それぞれの広告バナーには異なるキャッチコピーとデザインが使用されている．マーケティングチームは，どの広告がクリック率（広告が表示された回数に対する広告がクリックされた回数）を最も向上させるのかを調べるため，3つの広告キャンペーンを同時に2か月間実施し，毎日のA，B，Cのそれぞれの広告バナーのクリック率を調べた．その結果，次のようなデータが得られた．このデータをもとに，どの広告バナーが最もクリック率を向上させるのかを検証せよ（[リンク](./practice/example_multcomp.csv)）．

```{r include=FALSE}
#./practice/example_multcomp.csvの作成
set.seed(34)
num_samples <- 62
Date <- seq.Date(from = as.Date("2024-07-01"), by = "day", length.out = num_samples)
A <- round(rnorm(num_samples, mean = 0.08, sd = 0.02),4)
B <- round(rnorm(num_samples, mean = 0.05, sd = 0.003),4)
C <- round(rnorm(num_samples, mean = 0.06, sd = 0.004),4)

data <- tibble(
  Date = Date,
  A = A,
  B = B,
  C = C
)
write_csv(data, "./practice/example_multcomp.csv")

```
:::

2つのバナーでの比較だった場合には，単純にt検定を実施すれば良いが，今回の例の場合には3つのデータでの比較となっている．このように3つ以上のデータで，各データ間の平均の比較を行うような場合には，どのようにすればよいだろうか？

## 検定の多重性問題

こういうケースでシンプルに浮かぶ方法としては，「AとB」「BとC」「CとA」という形で，1対1の組み合わせを作り，それぞれの組み合わせで平均値の比較を行うというものである．例えば，平均値の値としてはA＜B＜Cとなっていたとして，上記の3つの組み合わせで，それぞれで差が有意であるかどうかを調べた結果，「ＢとＣの間には有意差はないが，AとB，CとAの間には有意差がある」という結果となった場合，「広告Ｂと広告Ｃの間にはそれほどの差はないが，AはB，Cに比べて広告としては弱い」という結論を出すことができる．

ただ，ここで注意しないといけないのは，***検定の多重性***という問題である

### そもそもP値とは

検定では一般に5%を基準として，これをP値が下回れば「有意である」と判定し，逆に上回っていた時には「測定時に生じた単なる誤差の可能性を否定できない」と判断する．このP値とは何かというと，分かりやすく述べれば「判定結果が誤っている確率」である．つまり，P値が5％であった場合には，本当は「単なる誤差」であるのに「有意である」と誤って判定する確率が5％ある，という意味である（このことから「有意水準」という言葉の変わりに「**危険率**」という言葉が用いられることもある）．このことから，「有意水準を下回っていれば有意とする」ということについて，なぜ「下回っていれば」なのかは，要するに「誤っている確率が５%未満であれば，十分に誤っている可能性は低いわけだから，結果を信頼してもよいだろう」と判断しているということである．ちなみに，「5%」を「十分に低い」の基準としているのは特段の理由があってのことではなく，統計学において経験上，設定された基準でしかない．

### 検定を多重化すると誤り率が上る
ある事柄Aについて，5%の有意水準で検定をしたときには，仮に「有意だ」と判定しても，それは5％の確率で誤っているということである．逆に言えば，95%の確率で正しいということである．
続けて，5％水準で別の事柄Bを検定して「有意だ」と判定した場合，同じようにその判定結果は95%の確率で正しい．

では，AとBの両方が正しい結果である，という確率はいくらであろうか？

Aが正しい確率：95%

Bが正しい確率：95%

⇒両方がそろって正しい確率：95%×95%＝90.25%となる．

これは言い換えると，AとBがそれぞれ個別には「95%の確率で正しい」となっていたとしても，AとB両方が同時に正しい結果である確率は90.25%となり，「AとBのいずれか一方が間違っている」，もしくは「両方間違っている」確率は約10%になるということである．

:::ref
より正確には，以下のような表となる．

|  | Bの判定は正しい | Bの判定は誤り |
|:---|:---|:---|
| **Aの判定は正しい** | 0.95×0.95＝0.9025 | 0.95×0.05＝0.0475 |
| **Aの判定は誤り** | 0.05×0.95＝0.0475 | 0.05×0.05＝0.025 |

この表から，AとBの両方が正しい確率は0.9025となる一方，AとBの少なくともどちらか一方が誤っている確率は0.0475×2＋0.025＝0.0975となる．
:::

当然ながら判定は「両方正しい結果」であってほしい．しかしながら，個別に5%水準で判定をして，それを組み合わせるということをすると，「両方ともに正しい結果である確率」は90%ほどとなってしまう．

これは，さらにCという事柄についての検定を行うとすると，A，B，Cの3つがそろって正しい結果である確率は，

95%×95%×95%＝85.73%

同様に事柄の検定の数を増やすと，

- 4つ：95% × 95% × 95% × 95%＝81.45%
- 5つ：95% × 95% × 95% × 95% × 95%＝77.38%
- 6つ：95% × 95% × 95% × 95% × 95%×95%＝73.51%

となってしまう．

このように，検定を多重に行ってしまうと，個々の検定の結果が正しい確率が95%（誤り率が5%）でも，多重に行った検定が全て正しい確率は95%を下回ってしまう．これが検定の多重性問題である．

### 検定の多重性問題の解決方法
「検定の多重性問題を解決する」というのは，つまりは「多重に行った検定が全て正しい確率が95%を下回らないようにすること」である．そのための方法には様々な方法があるが，もっとも単純で簡単な方法は，個別の検定を行う際の有意水準である「5%」という値を検定を行う回数で割った値を個別の検定の有意水準とすることである．

より具体的には，例えば，

‐2回の検定を行うのであれば，5%÷2＝2.5%を個々の検定の有意水準とする．
- 3回の検定を行うのであれば，5%÷3≒1.67%を個々の検定の有意水準とする．（端数は切り上げ）
- 4回の検定を行うのであれば，5%÷4＝1.25%を個々の検定の有意水準とする．
- 5回の検定を行うのであれば，5%÷5＝1%を個々の検定の有意水準とする．
- 6回の検定を行うのであれば，5%÷6≒0.84%を個々の検定の有意水準とする．（端数は切り上げ）

ということである．

このように補正すると，多重に行った検定が全て正しい確率は以下の通りとなる．

| 検定回数 |全て正しい確率 |
|---|---|
|2回の場合|97.5% × 97.5％＝95.06%|
|3回の場合|98.33% × 98.33% × 98.33%＝95.07%|
|4回の場合|98.75% × 98.75% × 98.75% × 98.75%＝95.09%|
|5回の場合|99% × 99% × 99% × 99% × 99%＝95.10%|
|6回の場合|99.16% × 99.16% × 99.16% × 99.16% × 99.16% × 99.16%＝95.06%|

<<<<<<< HEAD
このような、多重検定を行う際に、行う検定の数で有意水準を割った値を個々の有意性評価の基準とする方法をボンフェローニ（Bonferroni）補正と呼ぶ。実際には有意水準を補正するのではなく，有意確率の方を補正し，補正された有意確率が5\%を上回るか下回るかで評価することが多い．すなわち，

- 2回の検定であれば，一対比較時のP値を2倍する
- 3回の検定であれば，一対比較時のP値を3倍する
- 4回の検定であれば，一対比較時のP値を4倍する
- 5回の検定であれば，一対比較時のP値を5倍する

・・・

ということである

=======
このような，多重検定を行う際に，行う検定の数で有意水準を割った値を個々の有意性評価の基準とする方法をボンフェローニ（Bonferroni）補正と呼ぶ．
>>>>>>> 9b7ac0bd0970f87f315aa1a7cd3934d8df86290e

補正方法には他にもいくつかの方法があるが，ボンフェローニ補正は最もシンプルで直感的な方法であるため，手計算を行う際にはよく使われる．

ただ，ボンフェローニ補正は，検定の数が増えるにつれて有意水準が厳しくなるという性質があるため，検定の数が多い場合には，ホルム法やシダック法，ダンスカー法などの補正方法を用いることもある．


## 多重比較時のP値の補正方法

<<<<<<< HEAD
Rでは，`p.adjust()`という関数を用いて，上記のようなP値の補正を行うことができる．
第1引数には，多重比較時の個々の一対比較の結果のP値をまとめたものベクトルで与え，第2引数には，補正方法を指定する．

### 平均（T検定）の多重比較

先の例題では以下のようになる．

```{r}
mydata_multcomp <- read.csv(
  "./practice/example_multcomp.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

# データの確認
head(mydata_multcomp)

# AとBの比較
res_A_B<-t.test(mydata_multcomp$A, mydata_multcomp$B)
print(res_A_B)

# BとCの比較
res_B_C<-t.test(mydata_multcomp$B, mydata_multcomp$C)
print(res_B_C)

# CとAの比較
res_C_A<-t.test(mydata_multcomp$C, mydata_multcomp$A)
print(res_C_A)

# 各P値をベクトルにまとめる．
# それぞれのP値は$p.valueで取得できる
# わかりやすさのため，名前付きベクトルにしている．
P_values <- c(
  AとB=res_A_B$p.value, 
  BとC=res_B_C$p.value, 
  CとA=res_C_A$p.value
  )

print(P_values)

# 多重比較のP値の補正
p.adjust(P_values, method="bonferroni")


```

これらの出力結果から，今回の場合だと補正後でも，いずれの組み合わせでも有意な差があることが分かった．

このp.adjust()を用いた補正方法は，平均の比較，分散の比較，比率の比較いずれの比較においても用いることができる．

### 分散（F検定）の多重比較

分散の多重比較の例を示す．

:::practice
ある製造工程において、製品の重量を測定した結果、以下のようなデータが得られた。このデータをもとに、各工程間の重量のばらつきに有意な差があるかどうかを検証せよ（[リンク](./practice/example_multcomp_var.csv)）。
```{r include=FALSE}
#./practice/example_multcomp_var.csvの作成
set.seed(42)
num_samples <- 20
工程A <- rnorm(num_samples, mean = 100, sd = 5)
工程B <- rnorm(num_samples, mean = 110, sd = 5)
工程C <- rnorm(num_samples, mean = 105, sd = 5)

data <- tibble(
  工程A = 工程A,
  工程B = 工程B,
  工程C = 工程C
)
write_csv(data, "./practice/example_multcomp_var.csv")
```
:::

この場合，A-B，B-C，C-Aでそれぞれ分散の一対比較を行った後，そのP値を補正することになる．


```{r}
mydata_multcomp_var <- read.csv(
  "./practice/example_multcomp_var.csv",
  header=T,
  fileEncoding="UTF8"
) # データ読み込み

# データの確認
head(mydata_multcomp_var)

#分散の一対比較
res_AB <- var.test(mydata_multcomp_var$工程A, mydata_multcomp_var$工程B)
res_BC <- var.test(mydata_multcomp_var$工程B, mydata_multcomp_var$工程C)
res_CA <- var.test(mydata_multcomp_var$工程C, mydata_multcomp_var$工程A)

#P値をベクトルにまとめる
P_values_var <- c(
  AとB=res_AB$p.value, 
  BとC=res_BC$p.value, 
  CとA=res_CA$p.value
)
print(P_values_var) #P値の確認

#P値の補正
p.adjust(P_values_var, method = "holm")

# 参考：補正前のP値
p.adjust(P_values_var, method = "none")
```

この結果から、補正を行った結果、全ての組み合わせでP値が0.05を上回っていることが分かる。
なお，この例ではholm補正を行っているため，単純にP値を3倍しているわけではない．




### 比率（Z検定）の多重比較

比率の多重比較の例を示す．


:::practice
ある製造工程A，B, Cにおいて、製品の不良品率を測定したするためにランダムに1000個のサンプルを取り出し、不良品かどうかを調べた（良・不良）。その結果、以下のようなデータが得られた。このデータをもとに、各工程間の不良品率に有意な差があるかどうかを検証せよ（[リンク](./practice/example_multcomp_prop.csv)）。
```{r include=FALSE}
#./practice/example_multcomp_prop.csvの作成
set.seed(42)
num_samples <- 1000
工程A <- rbinom(num_samples, 1, 0.05)
工程B <- rbinom(num_samples, 1, 0.1)
工程C <- rbinom(num_samples, 1, 0.12)

工程A <- recode(工程A, `0`="良", `1`="不良")
工程B <- recode(工程B, `0`="良", `1`="不良")
工程C <- recode(工程C, `0`="良", `1`="不良")

data <- tibble(
  工程A = 工程A,
  工程B = 工程B,
  工程C = 工程C
)

write_csv(data, "./practice/example_multcomp_prop.csv")
```
:::

この場合もこれまでの多重比較と同様に，A-B，B-C，C-Aでそれぞれ比率の検定を一対比較で行った後，そのP値を補正することになる．

```{r}
mydata_multcomp_prop <- read.csv(
  "./practice/example_multcomp_prop.csv",
  header=T,
  fileEncoding="UTF8"
) # データ読み込み

# データの確認
mydata_multcomp_prop$工程A <- as.factor(mydata_multcomp_prop$工程A)
mydata_multcomp_prop$工程B <- as.factor(mydata_multcomp_prop$工程B)
mydata_multcomp_prop$工程C <- as.factor(mydata_multcomp_prop$工程C)
head(mydata_multcomp_prop)

#各工程の不良品数の取得
N_A_bad <- sum(mydata_multcomp_prop$工程A=="不良")
# 他にも以下のような書き方もある．
# その1
# res_A <- table(mydata_multcomp_prop$工程A)
# A_bad <- res_A["不良"]
# その2
# A_bad <- filter(mydata_multcomp_prop, 工程A=="不良")
# N_A <- nrow(A_bad)

N_B_bad <- sum(mydata_multcomp_prop$工程B=="不良")
N_C_bad <- sum(mydata_multcomp_prop$工程C=="不良")

#各工程の総数の取得 今回の場合最初から
#それぞれ1000件であることはわかっているが
#Rのコードで取得する
# 与えているのがベクトルデータなのでnrowではなくlegnth関数をつかう
N_A <- length(mydata_multcomp_prop$工程A)
N_B <- length(mydata_multcomp_prop$工程B)
N_C <- length(mydata_multcomp_prop$工程C)

#比率の検定
res_AB <- prop.test(c(N_A_bad, N_B_bad), c(N_A, N_B))
res_BC <- prop.test(c(N_B_bad, N_C_bad), c(N_B, N_C))
res_CA <- prop.test(c(N_C_bad, N_A_bad), c(N_C, N_A))

#P値をベクトルにまとめる
P_values_prop <- c(
  AとB=res_AB$p.value, 
  BとC=res_BC$p.value, 
  CとA=res_CA$p.value
)
print(P_values_prop) #P値の確認

#P値の多重比較のための補正
p.adjust(P_values_prop, method = "holm")
```

結果として，BとCの間には有意な差はないが，AとB，CとAの間には不良品率に有意な差がある，という結果となった．











## 平均の多重比較を行う別の方法
さて、先ほどの例では、A-B、B-C、C-Aの3つの組み合わせでそれぞれの平均値の差を検定を行った後、そのP値を補正する、という方法をとったが、Rでは`pairwise.t.test()`関数を用いることで、個別の検定を行うことなしに平均の多重比較を行うことができる．
第1引数には比較をしたい変数、第2引数にグループ分けに用いる属性変数を与える。

注意しなければならない点として、多重比較を行う場合にはデータはロング形式でなければならない。今回の例題のデータはワイド形式になっているので，以下の例ではまずはロング形式に変換している。


```{r}
mydata_multcomp <- read.csv(
  "./practice/example_multcomp.csv", 
  header=T, 
  fileEncoding="UTF8"
) # データ読み込み

#ワイド形式からロング形式に変換
mydata_multcomp_long <- pivot_longer(
  mydata_multcomp,
  cols=colnames(mydata_multcomp)[2:4],
  names_to = "広告",
  values_to= "クリック率" #測定変数に与える列名
)

#平均と標準偏差の確認
aggregate(クリック率~広告, data=mydata_multcomp_long, FUN=mean)
aggregate(クリック率~広告, data=mydata_multcomp_long, FUN=sd)

#多重比較の実施
pairwise.t.test(mydata_multcomp_long$クリック率, mydata_multcomp_long$広告)
```
結果の見方として，A-Bの比較のP値（補正済み）が`< 2e-16`となっている．これは，「$2.0 \times 10^{-16}$よりもさらに小さい」を意味しており，ほぼ0と見なせる値である．この結果から，AとBの間には有意な差があると結論づけることができる．
同様に，A-Cの比較のP値（補正済み）は$1.1\times 10^{-15}$であり，有意な差であるといえる．さらに，B-Cについても$4.6\times10^{-6}$であり ，有意な差があるといえる．

これら結果から，広告バナーはAが最もクリック率を向上させる効果があり，次いでCとなり，Bがもっとも効果が低いと結論づけることができる．

なお，pairwise.t.test()関数はデフォルトではホルム補正を行う．ボンフェローニ補正を行いたい場合には，p.adjust.method引数に`"bonferroni"`を指定することで行うことができる．また補正前の値を確認したければ`"none"`を指定するとよい．

また，補正の結果，P値が1を超えてしまうケースが出てくるが，その場合には「1」と表記される．

### 対応ありデータでの多重比較
対応ありデータでの多重比較を行う場合には，`pairwise.t.test()`関数の引数に`paired=TRUE`を指定することで行うことができる．

